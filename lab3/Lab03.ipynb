{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 - Decision Tree - II\n",
    "\n",
    "In this lab we are trying to do some more cleaning on our data, learn more on analyzing and preparing data, tune \n",
    "hyperparameters and evaluate our models.\n",
    "\n",
    "Let us get back to the state where we left last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data analysis and preparing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquire data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_merged.csv')\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in combine:\n",
    "    df.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "for df in combine:\n",
    "    df.drop(columns=['Ticket', 'PassengerId'], inplace=True)\n",
    "    df['Embarked'].fillna(df['Embarked'].mode(dropna=True)[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_encode = {\n",
    "    'Sex': {'male': 0, \"female\": 1},\n",
    "    'Embarked': {'S': 0, 'Q': 1, 'C': 2 }\n",
    "}\n",
    "\n",
    "for df in combine:\n",
    "    df.replace(num_encode, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation continued..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we observed last week, Age is a really good feature. Let's prepare it for the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completing a numerical continuous feature\n",
    "\n",
    "We can consider three methods to complete a numerical continuous feature.\n",
    "\n",
    "1. A simple way is to generate random numbers between mean and standard deviation.\n",
    "\n",
    "2. More accurate way of guessing missing values is to use other correlated features. In our case we note correlation \n",
    "among Age, Gender, and Pclass. Guess Age values using median values for Age across sets of Pclass and Gender feature \n",
    "combinations. So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on...\n",
    "\n",
    "3. Combine methods 1 and 2. Instead of guessing age values based on median, use random numbers between mean and \n",
    "standard deviation, based on sets of Pclass and Gender combinations.\n",
    "\n",
    "Method 1 and 3 can introduce random noise into our models. The results from multiple executions might vary. Because of \n",
    "that we will prefer method 2. But you can try any one of these methods in your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x239c3175fa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 514.88x475.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', height=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by preparing an empty array to contain guessed Age values based on Pclass x Gender combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate over Sex (0 or 1) and Pclass (1, 2, 3) to calculate guessed values of Age for the six combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment',None)\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "            age_guess = guess_df.median()\n",
    "            \n",
    "            guess_ages[i,j] = int(age_guess)\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            mask = dataset[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1)]     \n",
    "            if mask.empty:\n",
    "                continue\n",
    "            \n",
    "            dataset.loc[mask.index , 'Age'] = int(guess_ages[i, j])    \n",
    "                \n",
    "    # dataset.loc[:, 'Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    int64  \n",
      " 4   Age       891 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Fare      891 non-null    float64\n",
      " 8   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.head()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert the continuous feature to categorical feature to use it in our models. Let us create Age bands\n",
    "and determine correlations with Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toddler/baby</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Child</td>\n",
       "      <td>0.516854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elderly</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AgeBand  Survived\n",
       "0  Toddler/baby  0.625000\n",
       "1         Child  0.516854\n",
       "2         Adult  0.363636\n",
       "3       Elderly  0.125000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'],bins=[0,2,17,65,99], labels=['Toddler/baby','Child','Adult','Elderly'])\n",
    "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us replace Age with ordinals based on these bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age AgeBand  SibSp  Parch     Fare  Embarked  \n",
       "0  22.0       2      1      0   7.2500         0  \n",
       "1  38.0       2      1      0  71.2833         2  \n",
       "2  26.0       2      0      0   7.9250         0  \n",
       "3  35.0       2      1      0  53.1000         0  \n",
       "4  35.0       2      0      0   8.0500         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop('AgeBand', inplace=True, axis=1)\n",
    "for df in combine:\n",
    "    category = pd.cut(df.Age,bins=[0,2,17,65,99], labels=[0, 1, 2, 3])\n",
    "    df.insert(5,'AgeBand', category)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's Consider the Fare feature now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Survived', ylabel='Fare'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Survived', y='Fare', data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that the survived people on average has paid more fare compared to those who did not survive.  \n",
    "\n",
    "Let's complete the feature by assigning most frequent fare to all missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Fare'].fillna(dataset['Fare'].mode(dropna=True)[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's try to create Fare bands using quartile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FareBand</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>0.197309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>0.454955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>0.581081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FareBand  Survived\n",
       "0   (-0.001, 7.91]  0.197309\n",
       "1   (7.91, 14.454]  0.303571\n",
       "2   (14.454, 31.0]  0.454955\n",
       "3  (31.0, 512.329]  0.581081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like Fare bands give us good information on who has the least probability to survive. Let's make it an ordinal\n",
    "feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age FareBand AgeBand  SibSp  Parch     Fare  Embarked  \n",
       "0  22.0        0       2      1      0   7.2500         0  \n",
       "1  38.0        3       2      1      0  71.2833         2  \n",
       "2  26.0        1       2      0      0   7.9250         0  \n",
       "3  35.0        3       2      1      0  53.1000         0  \n",
       "4  35.0        1       2      0      0   8.0500         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(['FareBand'], axis=1, inplace=True)\n",
    "for df in combine:\n",
    "    category = pd.qcut(df.Fare, q=4, labels=[0, 1, 2, 3])\n",
    "    df.insert(5,'FareBand', category)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating new features extracting from existing features\n",
    "\n",
    "##### Title from Name\n",
    "\n",
    "We want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival,\n",
    " before dropping Name feature.\n",
    "\n",
    "In the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first \n",
    "word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AgeBand</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>488</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AgeBand    0   1    2  3\n",
       "Title                   \n",
       "Capt       0   0    0  1\n",
       "Col        0   0    2  0\n",
       "Countess   0   0    1  0\n",
       "Don        0   0    1  0\n",
       "Dr         0   0    7  0\n",
       "Jonkheer   0   0    1  0\n",
       "Lady       0   0    1  0\n",
       "Major      0   0    2  0\n",
       "Master    14  22    4  0\n",
       "Miss      10  41  131  0\n",
       "Mlle       0   0    2  0\n",
       "Mme        0   0    1  0\n",
       "Mr         0  22  488  7\n",
       "Mrs        0   4  121  0\n",
       "Ms         0   0    1  0\n",
       "Rev        0   0    6  0\n",
       "Sir        0   0    1  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Title'] = train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "pd.crosstab(train_df['Title'], train_df['AgeBand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>55</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>436</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1\n",
       "Title             \n",
       "Capt        1    0\n",
       "Col         1    1\n",
       "Countess    0    1\n",
       "Don         1    0\n",
       "Dr          4    3\n",
       "Jonkheer    1    0\n",
       "Lady        0    1\n",
       "Major       1    1\n",
       "Master     17   23\n",
       "Miss       55  127\n",
       "Mlle        0    2\n",
       "Mme         0    1\n",
       "Mr        436   81\n",
       "Mrs        26   99\n",
       "Ms          0    1\n",
       "Rev         6    0\n",
       "Sir         0    1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_df['Title'], train_df['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the above visualizations, we can note the following observations.\n",
    "\n",
    "- Most titles band Age groups accurately. For example: Master title has Age less than 17 years.\n",
    "- Survival among Title bands varies slightly.\n",
    "- Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).\n",
    "\n",
    "So this feature might be helpful to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Title'], axis=1, inplace=True)\n",
    "for df in combine:\n",
    "    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can replace many titles with a more common name or classify them as `Rare`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age FareBand AgeBand  SibSp  Parch     Fare  Embarked Title  \n",
       "0  22.0        0       2      1      0   7.2500         0    Mr  \n",
       "1  38.0        3       2      1      0  71.2833         2   Mrs  \n",
       "2  26.0        1       2      0      0   7.9250         0  Miss  \n",
       "3  35.0        3       2      1      0  53.1000         0   Mrs  \n",
       "4  35.0        1       2      0      0   8.0500         0    Mr  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's turn these categorical titles to ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age FareBand AgeBand  SibSp  Parch     Fare  Embarked  Title  \n",
       "0  22.0        0       2      1      0   7.2500         0      1  \n",
       "1  38.0        3       2      1      0  71.2833         2      3  \n",
       "2  26.0        1       2      0      0   7.9250         0      2  \n",
       "3  35.0        3       2      1      0  53.1000         0      3  \n",
       "4  35.0        1       2      0      0   8.0500         0      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can safely drop the Name feature from datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.drop('Name', inplace=True, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Family size from SibSp and Parch\n",
    "\n",
    "From our analysis last week, we figured out that 'SibSp' and 'Parch' are not very good features. So let us make a new \n",
    "feature called 'FamilySize', combining those features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FamilySize  Survived\n",
       "3           4  0.724138\n",
       "2           3  0.578431\n",
       "1           2  0.552795\n",
       "6           7  0.333333\n",
       "0           1  0.303538\n",
       "4           5  0.200000\n",
       "5           6  0.136364\n",
       "7           8  0.000000\n",
       "8          11  0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1    \n",
    "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see, this feature can be useful for our models. But it has a few too many categories. Let us create a feature \n",
    "called IsAlone from this feature to minimize complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop(['FamilySize'], axis=1, inplace=True)\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md"
    }
   },
   "source": [
    "Let us drop 'Family size'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age FareBand AgeBand  SibSp  Parch     Fare  \\\n",
       "0         0       3    0  22.0        0       2      1      0   7.2500   \n",
       "1         1       1    1  38.0        3       2      1      0  71.2833   \n",
       "2         1       3    1  26.0        1       2      0      0   7.9250   \n",
       "3         1       1    1  35.0        3       2      1      0  53.1000   \n",
       "4         0       3    0  35.0        1       2      0      0   8.0500   \n",
       "\n",
       "   Embarked  Title  IsAlone  \n",
       "0         0      1        0  \n",
       "1         2      3        0  \n",
       "2         0      2        1  \n",
       "3         0      3        0  \n",
       "4         0      1        1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset.drop(['FamilySize'], axis=1, inplace=True)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model, Predict and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's make training, validation and test sets from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "X_test = test_df.drop('Survived', axis=1)\n",
    "y_test = test_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "combine = [X_train, X_valid, X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's recreate the decision tree model we built last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "X_train_cat = X_train[['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']]\n",
    "X_valid_cat = X_valid[['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']]\n",
    "\n",
    "cat_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "cat_tree.fit(X_train_cat, y_train)\n",
    "y_pred = cat_tree.predict(X_valid_cat)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "You can get a different types of evaluation metrics from the sci-kit learn. First let's generate the confusion matrix \n",
    "for our prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150  17]\n",
      " [ 41  60]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The index mapping of the above matrix is as follows,\n",
    "\n",
    "- [0, 0] - True Positive\n",
    "- [0, 1] - False Negative\n",
    "- [1, 0] - False Positive\n",
    "- [1, 1] - True Negative\n",
    "\n",
    "Let's generate the classification report of our predicted data. Classification report contains information such as \n",
    "accuracy and precision, recall and f1-score for each output class.\n",
    "You can get more information on classification report here: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       167\n",
      "           1       0.78      0.59      0.67       101\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.78      0.75      0.76       268\n",
      "weighted avg       0.78      0.78      0.78       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Back to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us add the new features we curated and try to train a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.drop(['SibSp', 'Parch', 'Fare'], axis=1, inplace=True)\n",
    "X_test.drop(['SibSp', 'Parch', 'Fare'], axis=1, inplace=True)\n",
    "X_valid.drop(['SibSp', 'Parch', 'Fare'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       167\n",
      "           1       0.72      0.62      0.67       101\n",
      "\n",
      "    accuracy                           0.77       268\n",
      "   macro avg       0.76      0.74      0.75       268\n",
      "weighted avg       0.77      0.77      0.76       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entropy_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "entropy_tree.fit(X_train, y_train)\n",
    "y_pred = entropy_tree.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's try to plot this decision tree. We can use plot_tree() function in sci_kit learn to visualize the tree you modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(177.46009615384617, 211.7178947368421, 'X[6] <= 1.5\\nentropy = 0.963\\nsamples = 623\\nvalue = [382, 241]'),\n",
       " Text(86.11442307692307, 200.2736842105263, 'X[0] <= 1.5\\nentropy = 0.616\\nsamples = 367\\nvalue = [311, 56]'),\n",
       " Text(42.02884615384615, 188.82947368421054, 'X[2] <= 48.5\\nentropy = 0.918\\nsamples = 78\\nvalue = [52, 26]'),\n",
       " Text(26.111538461538462, 177.38526315789474, 'X[2] <= 47.5\\nentropy = 0.978\\nsamples = 58\\nvalue = [34, 24]'),\n",
       " Text(23.25, 165.94105263157894, 'X[3] <= 2.5\\nentropy = 0.959\\nsamples = 55\\nvalue = [34, 21]'),\n",
       " Text(5.723076923076923, 154.49684210526317, 'X[3] <= 1.0\\nentropy = 0.985\\nsamples = 21\\nvalue = [9, 12]'),\n",
       " Text(2.8615384615384616, 143.05263157894737, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(8.584615384615384, 143.05263157894737, 'X[2] <= 28.5\\nentropy = 0.918\\nsamples = 18\\nvalue = [6, 12]'),\n",
       " Text(5.723076923076923, 131.60842105263157, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(11.446153846153846, 131.60842105263157, 'X[2] <= 32.0\\nentropy = 0.971\\nsamples = 15\\nvalue = [6, 9]'),\n",
       " Text(8.584615384615384, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(14.307692307692308, 120.16421052631578, 'X[2] <= 38.0\\nentropy = 0.89\\nsamples = 13\\nvalue = [4, 9]'),\n",
       " Text(11.446153846153846, 108.72, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(17.16923076923077, 108.72, 'X[2] <= 42.5\\nentropy = 0.991\\nsamples = 9\\nvalue = [4, 5]'),\n",
       " Text(14.307692307692308, 97.27578947368421, 'X[5] <= 1.0\\nentropy = 1.0\\nsamples = 8\\nvalue = [4, 4]'),\n",
       " Text(11.446153846153846, 85.83157894736843, 'entropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(17.16923076923077, 85.83157894736843, 'entropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(20.03076923076923, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(40.776923076923076, 154.49684210526317, 'X[2] <= 41.0\\nentropy = 0.834\\nsamples = 34\\nvalue = [25, 9]'),\n",
       " Text(37.91538461538462, 143.05263157894737, 'X[2] <= 17.5\\nentropy = 0.894\\nsamples = 29\\nvalue = [20, 9]'),\n",
       " Text(35.05384615384615, 131.60842105263157, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(40.776923076923076, 131.60842105263157, 'X[2] <= 22.5\\nentropy = 0.863\\nsamples = 28\\nvalue = [20, 8]'),\n",
       " Text(37.91538461538462, 120.16421052631578, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(43.63846153846154, 120.16421052631578, 'X[2] <= 27.5\\nentropy = 0.918\\nsamples = 24\\nvalue = [16, 8]'),\n",
       " Text(28.615384615384617, 108.72, 'X[7] <= 0.5\\nentropy = 0.918\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(25.753846153846155, 97.27578947368421, 'X[2] <= 23.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(22.892307692307693, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(28.615384615384617, 85.83157894736843, 'X[5] <= 1.0\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(25.753846153846155, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(31.47692307692308, 74.38736842105263, 'X[2] <= 24.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(28.615384615384617, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(34.33846153846154, 62.943157894736856, 'X[2] <= 26.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(31.47692307692308, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(37.2, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(31.47692307692308, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(58.66153846153846, 108.72, 'X[5] <= 1.0\\nentropy = 0.764\\nsamples = 18\\nvalue = [14, 4]'),\n",
       " Text(55.800000000000004, 97.27578947368421, 'X[2] <= 30.0\\nentropy = 0.837\\nsamples = 15\\nvalue = [11, 4]'),\n",
       " Text(52.93846153846154, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(58.66153846153846, 85.83157894736843, 'X[7] <= 0.5\\nentropy = 0.89\\nsamples = 13\\nvalue = [9, 4]'),\n",
       " Text(51.50769230769231, 74.38736842105263, 'X[2] <= 36.5\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(45.784615384615385, 62.943157894736856, 'X[2] <= 33.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(42.92307692307693, 51.49894736842106, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(48.646153846153844, 51.49894736842106, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(57.23076923076923, 62.943157894736856, 'X[2] <= 37.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(54.36923076923077, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(60.09230769230769, 51.49894736842106, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(65.81538461538462, 74.38736842105263, 'X[2] <= 35.5\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(62.95384615384616, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(68.67692307692307, 62.943157894736856, 'entropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(61.52307692307692, 97.27578947368421, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(43.63846153846154, 143.05263157894737, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(28.973076923076924, 165.94105263157894, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(57.94615384615385, 177.38526315789474, 'X[2] <= 75.5\\nentropy = 0.469\\nsamples = 20\\nvalue = [18, 2]'),\n",
       " Text(55.08461538461538, 165.94105263157894, 'X[2] <= 51.5\\nentropy = 0.297\\nsamples = 19\\nvalue = [18, 1]'),\n",
       " Text(52.223076923076924, 154.49684210526317, 'X[3] <= 2.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(49.361538461538466, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(55.08461538461538, 143.05263157894737, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(57.94615384615385, 154.49684210526317, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(60.80769230769231, 165.94105263157894, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(130.2, 188.82947368421054, 'X[2] <= 26.5\\nentropy = 0.481\\nsamples = 289\\nvalue = [259, 30]'),\n",
       " Text(85.48846153846154, 177.38526315789474, 'X[0] <= 2.5\\nentropy = 0.358\\nsamples = 162\\nvalue = [151, 11]'),\n",
       " Text(82.62692307692308, 165.94105263157894, 'entropy = 0.0\\nsamples = 17\\nvalue = [17, 0]'),\n",
       " Text(88.35000000000001, 165.94105263157894, 'X[7] <= 0.5\\nentropy = 0.387\\nsamples = 145\\nvalue = [134, 11]'),\n",
       " Text(67.24615384615385, 154.49684210526317, 'X[2] <= 19.0\\nentropy = 0.619\\nsamples = 26\\nvalue = [22, 4]'),\n",
       " Text(64.38461538461539, 143.05263157894737, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(70.1076923076923, 143.05263157894737, 'X[2] <= 21.0\\nentropy = 0.722\\nsamples = 20\\nvalue = [16, 4]'),\n",
       " Text(67.24615384615385, 131.60842105263157, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(72.96923076923078, 131.60842105263157, 'X[2] <= 24.5\\nentropy = 0.503\\nsamples = 18\\nvalue = [16, 2]'),\n",
       " Text(70.1076923076923, 120.16421052631578, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(75.83076923076923, 120.16421052631578, 'X[2] <= 25.5\\nentropy = 0.567\\nsamples = 15\\nvalue = [13, 2]'),\n",
       " Text(72.96923076923078, 108.72, 'X[3] <= 1.0\\nentropy = 0.65\\nsamples = 12\\nvalue = [10, 2]'),\n",
       " Text(67.24615384615385, 97.27578947368421, 'X[5] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(64.38461538461539, 85.83157894736843, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(70.1076923076923, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(78.6923076923077, 97.27578947368421, 'X[5] <= 0.5\\nentropy = 0.503\\nsamples = 9\\nvalue = [8, 1]'),\n",
       " Text(75.83076923076923, 85.83157894736843, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(81.55384615384615, 85.83157894736843, 'X[5] <= 1.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(78.6923076923077, 74.38736842105263, 'entropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(84.41538461538461, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(78.6923076923077, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(109.45384615384616, 154.49684210526317, 'X[3] <= 2.5\\nentropy = 0.323\\nsamples = 119\\nvalue = [112, 7]'),\n",
       " Text(106.5923076923077, 143.05263157894737, 'X[2] <= 21.5\\nentropy = 0.292\\nsamples = 117\\nvalue = [111, 6]'),\n",
       " Text(91.56923076923077, 131.60842105263157, 'X[4] <= 1.5\\nentropy = 0.406\\nsamples = 37\\nvalue = [34, 3]'),\n",
       " Text(88.70769230769231, 120.16421052631578, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(94.43076923076923, 120.16421052631578, 'X[2] <= 18.5\\nentropy = 0.459\\nsamples = 31\\nvalue = [28, 3]'),\n",
       " Text(87.27692307692308, 108.72, 'X[3] <= 0.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(84.41538461538461, 97.27578947368421, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(90.13846153846154, 97.27578947368421, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(101.58461538461539, 108.72, 'X[2] <= 20.75\\nentropy = 0.391\\nsamples = 26\\nvalue = [24, 2]'),\n",
       " Text(95.86153846153846, 97.27578947368421, 'X[3] <= 0.5\\nentropy = 0.323\\nsamples = 17\\nvalue = [16, 1]'),\n",
       " Text(93.0, 85.83157894736843, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(98.72307692307693, 85.83157894736843, 'X[2] <= 19.5\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(95.86153846153846, 74.38736842105263, 'entropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(101.58461538461539, 74.38736842105263, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(107.3076923076923, 97.27578947368421, 'X[3] <= 0.5\\nentropy = 0.503\\nsamples = 9\\nvalue = [8, 1]'),\n",
       " Text(104.44615384615385, 85.83157894736843, 'entropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(110.16923076923077, 85.83157894736843, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(121.61538461538461, 131.60842105263157, 'X[2] <= 24.75\\nentropy = 0.231\\nsamples = 80\\nvalue = [77, 3]'),\n",
       " Text(118.75384615384615, 120.16421052631578, 'entropy = 0.0\\nsamples = 17\\nvalue = [17, 0]'),\n",
       " Text(124.47692307692309, 120.16421052631578, 'X[5] <= 0.5\\nentropy = 0.276\\nsamples = 63\\nvalue = [60, 3]'),\n",
       " Text(115.8923076923077, 108.72, 'X[3] <= 0.5\\nentropy = 0.183\\nsamples = 36\\nvalue = [35, 1]'),\n",
       " Text(113.03076923076924, 97.27578947368421, 'entropy = 0.0\\nsamples = 20\\nvalue = [20, 0]'),\n",
       " Text(118.75384615384615, 97.27578947368421, 'X[3] <= 1.5\\nentropy = 0.337\\nsamples = 16\\nvalue = [15, 1]'),\n",
       " Text(115.8923076923077, 85.83157894736843, 'X[2] <= 25.5\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(113.03076923076924, 74.38736842105263, 'entropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(118.75384615384615, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(121.61538461538461, 85.83157894736843, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(133.06153846153848, 108.72, 'X[3] <= 0.5\\nentropy = 0.381\\nsamples = 27\\nvalue = [25, 2]'),\n",
       " Text(130.2, 97.27578947368421, 'X[5] <= 1.5\\nentropy = 0.426\\nsamples = 23\\nvalue = [21, 2]'),\n",
       " Text(127.33846153846154, 85.83157894736843, 'entropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(133.06153846153848, 85.83157894736843, 'entropy = 0.439\\nsamples = 11\\nvalue = [10, 1]'),\n",
       " Text(135.92307692307693, 97.27578947368421, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(112.31538461538462, 143.05263157894737, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(174.91153846153847, 177.38526315789474, 'X[2] <= 32.25\\nentropy = 0.609\\nsamples = 127\\nvalue = [108, 19]'),\n",
       " Text(156.66923076923078, 165.94105263157894, 'X[2] <= 30.75\\nentropy = 0.838\\nsamples = 56\\nvalue = [41, 15]'),\n",
       " Text(144.5076923076923, 154.49684210526317, 'X[3] <= 1.5\\nentropy = 0.689\\nsamples = 38\\nvalue = [31, 7]'),\n",
       " Text(141.64615384615385, 143.05263157894737, 'X[2] <= 27.5\\nentropy = 0.784\\nsamples = 30\\nvalue = [23, 7]'),\n",
       " Text(135.92307692307693, 131.60842105263157, 'X[5] <= 1.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(133.06153846153848, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(138.7846153846154, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(147.36923076923077, 131.60842105263157, 'X[2] <= 28.75\\nentropy = 0.691\\nsamples = 27\\nvalue = [22, 5]'),\n",
       " Text(144.5076923076923, 120.16421052631578, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(150.23076923076923, 120.16421052631578, 'X[5] <= 0.5\\nentropy = 0.773\\nsamples = 22\\nvalue = [17, 5]'),\n",
       " Text(144.5076923076923, 108.72, 'X[3] <= 0.5\\nentropy = 0.65\\nsamples = 18\\nvalue = [15, 3]'),\n",
       " Text(141.64615384615385, 97.27578947368421, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(147.36923076923077, 97.27578947368421, 'X[0] <= 2.5\\nentropy = 0.845\\nsamples = 11\\nvalue = [8, 3]'),\n",
       " Text(141.64615384615385, 85.83157894736843, 'X[2] <= 29.5\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(138.7846153846154, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(144.5076923076923, 74.38736842105263, 'entropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(153.09230769230768, 85.83157894736843, 'X[2] <= 30.25\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(150.23076923076923, 74.38736842105263, 'X[2] <= 29.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(147.36923076923077, 62.943157894736856, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(153.09230769230768, 62.943157894736856, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(155.95384615384614, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(155.95384615384614, 108.72, 'X[2] <= 29.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(153.09230769230768, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(158.81538461538463, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(147.36923076923077, 143.05263157894737, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(168.83076923076922, 154.49684210526317, 'X[5] <= 0.5\\nentropy = 0.991\\nsamples = 18\\nvalue = [10, 8]'),\n",
       " Text(165.96923076923076, 143.05263157894737, 'X[3] <= 0.5\\nentropy = 1.0\\nsamples = 16\\nvalue = [8, 8]'),\n",
       " Text(158.81538461538463, 131.60842105263157, 'X[2] <= 31.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(155.95384615384614, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(161.6769230769231, 120.16421052631578, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(173.12307692307692, 131.60842105263157, 'X[7] <= 0.5\\nentropy = 0.996\\nsamples = 13\\nvalue = [6, 7]'),\n",
       " Text(167.4, 120.16421052631578, 'X[2] <= 31.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(164.53846153846155, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(170.26153846153846, 108.72, 'X[3] <= 2.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(167.4, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(173.12307692307692, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(178.84615384615384, 120.16421052631578, 'X[2] <= 31.5\\nentropy = 0.971\\nsamples = 10\\nvalue = [4, 6]'),\n",
       " Text(175.98461538461538, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(181.7076923076923, 108.72, 'X[3] <= 2.0\\nentropy = 1.0\\nsamples = 8\\nvalue = [4, 4]'),\n",
       " Text(178.84615384615384, 97.27578947368421, 'X[0] <= 2.5\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(175.98461538461538, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(181.7076923076923, 85.83157894736843, 'entropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(184.56923076923078, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(171.6923076923077, 143.05263157894737, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(193.15384615384616, 165.94105263157894, 'X[0] <= 2.5\\nentropy = 0.313\\nsamples = 71\\nvalue = [67, 4]'),\n",
       " Text(187.43076923076924, 154.49684210526317, 'X[3] <= 1.5\\nentropy = 0.544\\nsamples = 24\\nvalue = [21, 3]'),\n",
       " Text(184.56923076923078, 143.05263157894737, 'X[2] <= 34.5\\nentropy = 0.696\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(181.7076923076923, 131.60842105263157, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(187.43076923076924, 131.60842105263157, 'X[2] <= 40.5\\nentropy = 0.592\\nsamples = 14\\nvalue = [12, 2]'),\n",
       " Text(184.56923076923078, 120.16421052631578, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(190.2923076923077, 120.16421052631578, 'X[2] <= 45.0\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(187.43076923076924, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(193.15384615384616, 108.72, 'X[2] <= 60.5\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(190.2923076923077, 97.27578947368421, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(196.01538461538462, 97.27578947368421, 'X[2] <= 64.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(193.15384615384616, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(198.87692307692308, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(190.2923076923077, 143.05263157894737, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(198.87692307692308, 154.49684210526317, 'X[2] <= 44.5\\nentropy = 0.149\\nsamples = 47\\nvalue = [46, 1]'),\n",
       " Text(196.01538461538462, 143.05263157894737, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0]'),\n",
       " Text(201.73846153846154, 143.05263157894737, 'X[2] <= 45.25\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(198.87692307692308, 131.60842105263157, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(204.6, 131.60842105263157, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(268.8057692307692, 200.2736842105263, 'X[0] <= 2.5\\nentropy = 0.852\\nsamples = 256\\nvalue = [71, 185]'),\n",
       " Text(233.2153846153846, 188.82947368421054, 'X[6] <= 4.5\\nentropy = 0.496\\nsamples = 138\\nvalue = [15, 123]'),\n",
       " Text(223.20000000000002, 177.38526315789474, 'X[5] <= 0.5\\nentropy = 0.278\\nsamples = 125\\nvalue = [6, 119]'),\n",
       " Text(220.33846153846153, 165.94105263157894, 'X[3] <= 2.5\\nentropy = 0.368\\nsamples = 85\\nvalue = [6, 79]'),\n",
       " Text(214.6153846153846, 154.49684210526317, 'X[2] <= 23.0\\nentropy = 0.511\\nsamples = 44\\nvalue = [5, 39]'),\n",
       " Text(211.75384615384615, 143.05263157894737, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 13]'),\n",
       " Text(217.47692307692307, 143.05263157894737, 'X[2] <= 27.5\\nentropy = 0.637\\nsamples = 31\\nvalue = [5, 26]'),\n",
       " Text(210.32307692307694, 131.60842105263157, 'X[2] <= 25.0\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(204.6, 120.16421052631578, 'X[7] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(201.73846153846154, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(207.46153846153845, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(216.04615384615386, 120.16421052631578, 'X[3] <= 1.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(213.1846153846154, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(218.90769230769232, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(224.63076923076923, 131.60842105263157, 'X[2] <= 37.0\\nentropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(221.76923076923077, 120.16421052631578, 'entropy = 0.0\\nsamples = 16\\nvalue = [0, 16]'),\n",
       " Text(227.4923076923077, 120.16421052631578, 'X[2] <= 44.5\\nentropy = 0.764\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(224.63076923076923, 108.72, 'X[6] <= 2.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(221.76923076923077, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(227.4923076923077, 97.27578947368421, 'X[2] <= 42.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(224.63076923076923, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(230.35384615384615, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(230.35384615384615, 108.72, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(226.06153846153848, 154.49684210526317, 'X[2] <= 3.0\\nentropy = 0.165\\nsamples = 41\\nvalue = [1, 40]'),\n",
       " Text(223.20000000000002, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(228.92307692307693, 143.05263157894737, 'entropy = 0.0\\nsamples = 40\\nvalue = [0, 40]'),\n",
       " Text(226.06153846153848, 165.94105263157894, 'entropy = 0.0\\nsamples = 40\\nvalue = [0, 40]'),\n",
       " Text(243.23076923076923, 177.38526315789474, 'X[1] <= 0.5\\nentropy = 0.89\\nsamples = 13\\nvalue = [9, 4]'),\n",
       " Text(240.36923076923077, 165.94105263157894, 'X[7] <= 0.5\\nentropy = 0.684\\nsamples = 11\\nvalue = [9, 2]'),\n",
       " Text(237.5076923076923, 154.49684210526317, 'X[2] <= 60.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(234.64615384615385, 143.05263157894737, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(240.36923076923077, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(243.23076923076923, 154.49684210526317, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(246.09230769230768, 165.94105263157894, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(304.3961538461539, 188.82947368421054, 'X[2] <= 38.5\\nentropy = 0.998\\nsamples = 118\\nvalue = [56, 62]'),\n",
       " Text(284.0076923076923, 177.38526315789474, 'X[3] <= 0.5\\nentropy = 0.991\\nsamples = 110\\nvalue = [49, 61]'),\n",
       " Text(251.81538461538463, 165.94105263157894, 'X[2] <= 25.5\\nentropy = 0.874\\nsamples = 34\\nvalue = [10, 24]'),\n",
       " Text(248.95384615384617, 154.49684210526317, 'X[2] <= 21.5\\nentropy = 0.811\\nsamples = 32\\nvalue = [8, 24]'),\n",
       " Text(246.09230769230768, 143.05263157894737, 'X[5] <= 1.5\\nentropy = 0.877\\nsamples = 27\\nvalue = [8, 19]'),\n",
       " Text(243.23076923076923, 131.60842105263157, 'X[2] <= 15.0\\nentropy = 0.932\\nsamples = 23\\nvalue = [8, 15]'),\n",
       " Text(240.36923076923077, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(246.09230769230768, 120.16421052631578, 'X[2] <= 17.0\\nentropy = 0.902\\nsamples = 22\\nvalue = [7, 15]'),\n",
       " Text(243.23076923076923, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(248.95384615384617, 108.72, 'X[2] <= 18.5\\nentropy = 0.918\\nsamples = 21\\nvalue = [7, 14]'),\n",
       " Text(243.23076923076923, 97.27578947368421, 'X[5] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(240.36923076923077, 85.83157894736843, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(246.09230769230768, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(254.6769230769231, 97.27578947368421, 'X[2] <= 20.0\\nentropy = 0.852\\nsamples = 18\\nvalue = [5, 13]'),\n",
       " Text(251.81538461538463, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(257.53846153846155, 85.83157894736843, 'X[7] <= 0.5\\nentropy = 0.896\\nsamples = 16\\nvalue = [5, 11]'),\n",
       " Text(254.6769230769231, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(260.4, 74.38736842105263, 'X[5] <= 0.5\\nentropy = 0.837\\nsamples = 15\\nvalue = [4, 11]'),\n",
       " Text(257.53846153846155, 62.943157894736856, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(263.26153846153846, 62.943157894736856, 'entropy = 0.779\\nsamples = 13\\nvalue = [3, 10]'),\n",
       " Text(248.95384615384617, 131.60842105263157, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(251.81538461538463, 143.05263157894737, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(254.6769230769231, 154.49684210526317, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(316.2, 165.94105263157894, 'X[2] <= 30.5\\nentropy = 1.0\\nsamples = 76\\nvalue = [39, 37]'),\n",
       " Text(310.4769230769231, 154.49684210526317, 'X[2] <= 1.375\\nentropy = 0.993\\nsamples = 69\\nvalue = [38, 31]'),\n",
       " Text(307.61538461538464, 143.05263157894737, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(313.33846153846156, 143.05263157894737, 'X[3] <= 2.5\\nentropy = 0.987\\nsamples = 67\\nvalue = [38, 29]'),\n",
       " Text(303.32307692307694, 131.60842105263157, 'X[2] <= 27.5\\nentropy = 0.997\\nsamples = 58\\nvalue = [31, 27]'),\n",
       " Text(297.6, 120.16421052631578, 'X[2] <= 25.5\\nentropy = 1.0\\nsamples = 53\\nvalue = [27, 26]'),\n",
       " Text(294.73846153846154, 108.72, 'X[6] <= 2.5\\nentropy = 0.995\\nsamples = 50\\nvalue = [27, 23]'),\n",
       " Text(280.4307692307692, 97.27578947368421, 'X[5] <= 0.5\\nentropy = 0.918\\nsamples = 27\\nvalue = [18, 9]'),\n",
       " Text(274.7076923076923, 85.83157894736843, 'X[4] <= 1.5\\nentropy = 0.696\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(271.84615384615387, 74.38736842105263, 'X[3] <= 1.5\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(268.9846153846154, 62.943157894736856, 'X[2] <= 3.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(266.12307692307695, 51.49894736842106, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(271.84615384615387, 51.49894736842106, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(274.7076923076923, 62.943157894736856, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(277.5692307692308, 74.38736842105263, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(286.15384615384613, 85.83157894736843, 'X[5] <= 1.5\\nentropy = 0.994\\nsamples = 11\\nvalue = [5, 6]'),\n",
       " Text(283.2923076923077, 74.38736842105263, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(289.0153846153846, 74.38736842105263, 'X[2] <= 7.0\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(286.15384615384613, 62.943157894736856, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(291.8769230769231, 62.943157894736856, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(309.04615384615386, 97.27578947368421, 'X[2] <= 5.0\\nentropy = 0.966\\nsamples = 23\\nvalue = [9, 14]'),\n",
       " Text(303.32307692307694, 85.83157894736843, 'X[2] <= 3.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(300.46153846153845, 74.38736842105263, 'X[5] <= 0.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(297.6, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(303.32307692307694, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(306.18461538461537, 74.38736842105263, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(314.7692307692308, 85.83157894736843, 'X[7] <= 0.5\\nentropy = 0.9\\nsamples = 19\\nvalue = [6, 13]'),\n",
       " Text(311.9076923076923, 74.38736842105263, 'X[3] <= 1.5\\nentropy = 0.852\\nsamples = 18\\nvalue = [5, 13]'),\n",
       " Text(309.04615384615386, 62.943157894736856, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(314.7692307692308, 62.943157894736856, 'X[2] <= 8.0\\nentropy = 0.94\\nsamples = 14\\nvalue = [5, 9]'),\n",
       " Text(311.9076923076923, 51.49894736842106, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(317.63076923076926, 51.49894736842106, 'X[2] <= 9.5\\nentropy = 0.89\\nsamples = 13\\nvalue = [4, 9]'),\n",
       " Text(314.7692307692308, 40.05473684210526, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(320.4923076923077, 40.05473684210526, 'X[4] <= 1.5\\nentropy = 0.946\\nsamples = 11\\nvalue = [4, 7]'),\n",
       " Text(317.63076923076926, 28.610526315789485, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(323.3538461538462, 28.610526315789485, 'X[5] <= 1.5\\nentropy = 0.881\\nsamples = 10\\nvalue = [3, 7]'),\n",
       " Text(317.63076923076926, 17.166315789473686, 'X[2] <= 24.5\\nentropy = 0.65\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(314.7692307692308, 5.722105263157886, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(320.4923076923077, 5.722105263157886, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(329.0769230769231, 17.166315789473686, 'X[2] <= 22.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(326.2153846153846, 5.722105263157886, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(331.9384615384615, 5.722105263157886, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(317.63076923076926, 74.38736842105263, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(300.46153846153845, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(309.04615384615386, 120.16421052631578, 'X[6] <= 2.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(306.18461538461537, 108.72, 'entropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(311.9076923076923, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(323.3538461538462, 131.60842105263157, 'X[2] <= 5.5\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(320.4923076923077, 120.16421052631578, 'X[4] <= 0.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(317.63076923076926, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(323.3538461538462, 108.72, 'X[6] <= 3.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(320.4923076923077, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(326.2153846153846, 97.27578947368421, 'X[2] <= 3.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(323.3538461538462, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(329.0769230769231, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(326.2153846153846, 120.16421052631578, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(321.9230769230769, 154.49684210526317, 'X[6] <= 2.5\\nentropy = 0.592\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(319.0615384615385, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(324.7846153846154, 143.05263157894737, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(324.7846153846154, 177.38526315789474, 'X[2] <= 54.0\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(321.9230769230769, 165.94105263157894, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(327.6461538461539, 165.94105263157894, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAADnCAYAAABWmT4TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABCSUlEQVR4nO29e3wcx3Xn+y2AAzQgkcSQBAESfIAPiRQl0XpQEilRNGU7XsevdazYuV5n8/DdxBtvcn2dbN7ZXMfJbl4fO+u7d53rXfs63qyTbPzIw47XidcSKZGyJYskTFKiKRIkAEIkAPMBQBAwBCnW/aO7gUFPVU9XTz8GRP0+n/5o1Kyuc+rUqTOFmj7nJ6SUWFhYWFhkh4a8FbCwsLBYaLCB18LCwiJj2MBrYWFhkTFs4LWwsLDIGDbwWlhYWGQMG3gtLCwsMoYNvBYWFhYZwwZeCwsLi4xhA6/FTYWWlpYhIYSMcrW0tAzlra/FwoSwmWsWNxOEEFJKycGDBykUCqxZs4br16/T3t7OyMgIAOvXr/fbIqUUeeprsTBhA6/FTQU/8A4PD7NixQpeffVVlixZomtrA69FLliUtwIWFnEghLgFWA90By6eeuopyjcUd9xxB+fPn+fq1auUSiU6OzvZsmWL38/Hgb7yS0r5SjajsFiosDtei7pESGD1r8VAP4GgCfyllJIDBw4wPDxMe3s7Ukq6u7spFoscOXIEx3F46KGHEEIA/Iqi75Ki35nLBmaLWmEDr0UuEEK0Eh5Yl6AOrP41IqW8oehXRvVp1VGDcKPxihC9uoGpEL36bWC2qAYbeC1SQYTAupTwwDqsCqwR5Mp9+/bR3d3N4OAgt912G9euXWNwcJAbN26wevVqLl68SKlUYvfu3cZnvF5gbg8ZVzcwGTKuPinlhOm4LG4u2MBrEQtCiBbUgXUDKQbWamhpaRkqlUodUdo6jjM8NTXVmaT8GIH5LJU7ZhuYb3LYwGuhREhg9a824ByVgaPPu5dKYJ3vCARm/0sqeE0QvmN+NRttLdKCDbwLFF5gXYc+sBaBAfQBYMgG1uThBeaVhO+YXyH8jNkG5jqHDbw3KYQQDuE71iLujrVPc12wgbX+4AXmDvTzuh51YPb/MumXUk5mpK6FBjbwZoCo544mZ45eYA3bsS5HfxTQhw2sNyWEEA3od8wbcH1mnPAdc+TAnIZvLwTYwJsBor7iVP56kxBiCfAgIKj84aqb2cDap7kuSClfS2gIFjcJvMBcbcc8hvqHv2nguJRypKw/Y9+2sIE3E/jOuW/fPpqamuju7lbWDwgE3q8APwI8gfpPRhtYLRKHIjCXf9m/EXhOSrmrrL3StwuFAgMDA3R2dlb4toUNvJlACCH379/P+Pg4ra2tlEolduzYMZPGOj09zZo1a9i4cWN54BVAo5Tyes7qW1gAIIRoBG6Ub3HDfHtsbAzHcejo6GDDhg028JbBBt6U4J3B7gLeAPxW1D/HgH8JPCGlPJ+qghYWNUAIUQBeD3zTwLcbIqcV3uSwRXISghBiEXA/7p9jbwAeAl7APSrQ1g44deoUS5Ys4bbbbvO7+hHgk0KIEeBb3vP7pJSXsx6ThUU5vM3EDwGPA+8AToPat9va2jh69ChNTU089NBDfhdnvSO0rwDPLOQfd20h9JgQQjQIIbYLIf5PIcTfAxeB/4r7i/IngTVSyp1Syt8AeO2119ixYweNjY3ccccdLFq0iBMnTtDU1MSNGzd49tlnAZBSPu718X7czK+fAfqEEIeEEH8shHiLEOLWHIZssQAhhFgshHivEOJ/AEPALwGHgXuklA8BrF27ls7OTrZu3crmzZsplUo0NDSwdOlSSqUSL7/8st/dO3B/uPvPwMtCiD8VQvyQt3teULBHDRHhnbluwt3NvhF4DPe1HH9X+mT5r73liPrKTXNz84iqnRCiCfcNB383fT9wxJP7LeBZKeXVOOOysAhCCLEMN0g+DuwFDuLuUv8u6ONxXycTQtyG+9fdu4HbgK95Mv5JSjmV0FDqFjbwhkAI0YUb6PyrwGygfUJK2Z+TXrcAjzD7JbAVeIbZQHzEvvFgYQIhRCezgfAhXD/6MvA1KeVoyrLXAu/CDfT3Av/oyf76zVrpzQbeMnjf9I8xG9DagX3MBtuT9fjjgBCiiPtDh6/3KmA/3hcE8GI96m2RL4QQ3biB9t3AncDXcXed38gr7VgIsRJ4p6fTblw//jLwVSnlpTx0SgMLOvB6Z6WPMhuwNuP+WeUH2p75+AOAt3vxd+lvBFqY3Q0/IaU8m6N6FjlCCHEHs8F2HfB3uIHtiXo7rhJCLAXejqvrm4DncL8Y/lZKeSFP3WrFggq8QohmYCezAeke4Hlmg9J3pZTTuSmYEoQQG5g9H34DbllCf8xP4lYSWziOsMAghHgL8GHcrLQluMHrK8CB+fKeuFff+S24QfhtuG8M9eAG4f+Vo2qxMC8Dr+mBvver6TQuc8BxZoPOwYVWMMT7kXAbs4H4MdzF2O2fWdv8+/pFnLkRQnwKN2i9D3dzMe/+iiuH92PzG4HP4B7/vcH/tyj2qQe/nZeBt5zC23EcVq1axfXr11m+fDnPP//8HE4tKaXwgs2vA38hpezLWf26glce8j3Af/cXpM6+hUKBc+fOIaWcY998R7CwoKOvX758OcePH1/wKbpCCHngwIE5flssFjl8+HBFXMhVz/kceKtReNeDgecjrH3rF3ZuwiGEkENDQ3Vvm3mbuRZG4T09PU1HRyT2F4sAhBDLQW9fIQSjo6N0d3f77RfNl3PCmwVhc1MqlVi5cmWO2uWP73//+zOfy+NCqVRi1apVOWo2i3mbubZnzx4aGxu5ePEiQghOnDhBsVhk27ZtNDQ0sGHDhrxVnBcQQiwVQrxDCPEJIUQPcAagoaFhxrYAU1NTbNiwgfHxcRzHYf369X4Xl4QQXxNC/KIQ4l6vupVFilDNzebNm5mcnKRUKi1Y3/d9TxUX7rzzTtra2rhwoT5ehpjXRw0R2uX+J0W9IZB88QbgDuBZvOw73Lc8pg0Kn6zEzW7y339uZ+47xCfsGxPJwfq+GkKIvcDHgfuq2cfz291SyoOpK6bTYT6tCS9ofNJxnJ8qlUqN1do7jnOtVCrdlleGWT3AK2ziv0L3GG5m0GHcIPsE8J3g+5sGKc4/KJVKc/6uFUKsZjYIPwa0erJ8eb02EMdHLXNzM8JLPf4j3FdDf61QKHzq2rVry8KecRxnrFQqjeNuOH5VSnkmfU0DkFLOiwt4ADgJ/BmwWPHvxcD/LwN+GRgBfixv/TO0UwF4GPhN3FfmJoDvAL+PW1nqlpj9FqPcU7TpBn4a+HPgZVzWjM8DPwWsy9te8+3CTXYYxS3CVDEPwAdxX518NG9dU7bDMuA/4han+lXA0bQLxoWi999W4LeAS8AfA21Z6j8vdrxCiN/DDSTvk1L+leGzO4B/ABZJKZenoV+e8IpT38vsDvMRoJfZo4OnpZRj+Wk4C++1vtuY1fUxXGJGX9cn5TzPSEob3ju5p6SUf6L59wbgG8DvSSmfylS5DOC9w/tvgN8Avgh8VGqKU0XsrxP4Xdw05d8FPi2lvJaErqFy50ng3Yz7Db8v5vN3Ao9LKT+WqGI5wFtYdzEbvPYA55kNXvvlPMlp9wLxncweTbweGGZ2LPuklBfz09CiniCEeDde8Rzgl6WULybY93bcM+JHvL7/c1J9K+XNh8C7kOEFpy3MBtq9wBVmz0z3SSmHc1MwQXi799cxG4h34/LL+YH4KZlypSyL+oUXHH9MSvmbKfUvgE/h/u7x+TRkzMjKI/DmnZKapfyossrlCSHagL/CPX96A+6Znf+WwJNSysFadJov8FK972c2EO8Evu9dvVLKj/pt8/apJJB0umu9p8/OhzlLy4a5BN68X4nJUn5UWeXyhBCP4Z7T/R/AN4GzkTu5ieEVOXoI93yvS0p5d9m/5epTSSDKGEz0T7q/pDEf5iwtG+YaePft28fixYvn1FoYHBxkdHQ01ZxqnfylS5fS09OTaE63iEh/7bWt26BQ7/Bz9BsbG1m3bt1Mjv6LL84eA9ZLnr4OQgj55JNP0tLSwtq1a7l+/TpSSoaGhmLVYPD7W7lyJW1tbTX3lzTK10ZSY05Dx6BfSSnp6+tDCMGePXti6ZdbltFTTz3FxMQEY2NjM8Hu1KlTjI6OMj09zUsvvZS5/LNnz9LW1oYQgtOnTycuq1QqzcgaHnaPZfv6+lIf60LB6Ogok5OT9PT0cPbsWaampmhubgagVColOqdpYWJigldffXXGT65cuYLjOLH9ZGJigqGhoTn9lUolhoaGUtDeHP7aCI4Z3LXR35//K/hBv2ppaWHp0qU0Nzdz8GC8HAx71JCy/DhHDbXIW6jI26eSwEI6ahBCbMQ9p4/SFnKihk/LhrkWydHRQh8/fpwHH3wwF9lHjx7lwQcfnNkppSlv+fLlHDt2jEWLFvHAAw8kKm8hwfs1Wmvj3t5eHMdhy5YteataFV/+8peV+pdKpXKa9MgI87usfU4I0Q78GC6D9qYw/Xp7e5mcnGTXrl3+4yeEEF/ALe3am6niIXoePXo0Vn+5HTXs37+/ghZ6aGiI0dFRHMfh/PnzqcpX0a339/ezefNmnn/++URlqcY6NjbGsWPHWLZsGY7jlFNgWxhACLEJlxyxwsZTU1McOnQIx3EYHR2dsbH3TF0i6JOHDh2iubmZUqkU689ulZ/7NvGPu9KEEOIWIcT7hRBfB04Bu3ATFbrC9Gtra6OhoaF8zD8NdADfFkJ8Wwjx88LlZ0sdqvU7Pj7O4OBgebEoMySVAmdyOY4zBMhql+M4Q/NdflRZaY73ZryAJtzi9heBXzaY03HvmV8HmvIeh6mvmPhI0v0ZzE0BeCvwBdz05q/j7nJvNdUvqGPUvut1TmbGkbezAXd7hizivq+6JmP5b8EtsLEXuIybWpyWrA8AF7zPP0vMugkL/cLNLjruLbruGM9vAP4ncAx4OO/xKPRbj/sn+SLgKrCjxv5We8GpAZdvb3cKOgvc3ez/g1sf5dvALwArU7TTrd64vu4F4S94saSQgqzFuNRhm4CP4FIOxe8vbycrG1gDMAbszEl+p2fYlhRl/HvgSN62ns8X8BJu4Z/34v04HLMf4fVxERjNe1whel4gwSJPuEWKfjrB/rbiHh304ia2/DtgUw52Wgn8vBfwR7wvgF21+Eig/27gVVzG7h8GflBLfzZl2GJeQQjxQdwvr+cS6m87bkLG+6RdDJEghFgF/G+4u83VuFmWXwAO14MNvTP8f4GrXwH4C+ALUsrvhz6YJbL8VsrrzGk+yc9Cj3q68j7vz9tP8jzXNbU98CbgNdxaIZ/z/r8xbx/SXbh/1dwPfAK3kNQUbv3dXOa6/Mp0x5v3e4XzQX4WetQT6vH92yz9JM93d01t71X5+1Xgg1LKqSj61Au8Akx/iFu976tl93OJCZkH3gMHDrBo0aKZ9MBCocCOHTtCXx9LqkiGL7+c+llKya5du0K5mOLI1xXXkNKl5l6xYgWLFy9Wpkh6ui6YwKuj4+7s7Ew9fTxMJyGENsU7ycAbZ02A2i/9/oL+9fDDDyv7C9reHycw897wzeyLOv/bsmWLMiY0Nzdz9epVRU8uosaKzAOvinpZCMG+fftm2pUzg95zzz04jpOYk2clXwgh9+/fT7l99+7di5TVqbl9nW5WZy+HEEJevnwZx3G4du1aXdhD5ydp6BPmk0H/ieKXJv3t3buXerN91tD5ny4m3HvvvYnEiswz11TUy+Ayg/qZISdOnKC7u5tiscgLL7yQm/zly5dz9uzZ2LIaGhrmZLtAOC19qVRi48aNrF27NrbM+Yhjx44pbTI2NkZDQwMdHZGqaiYKHUV4a2srTU1NqcuCSv/xmZ6/973vJdIfhNu+ra2NlpaWxMZZr1DZANQxAeDixYtz5mTz5s0MDg4aZbtmvuN9+umnK1Lvuru7CdMjyd1FVvJVZ0deP6Fpkn5q6M28yyiHbk7a2to4ffo027dvp1AoZL7jVem0bNkyzp8/z+23305DQ0OuPuk9q9zxRu1PCIGqbbFY5MiRIzz66KM0NDTc1L5oan9/DYf0F8lWmQReIcRi4A+AD6nkdXZ2hqYvJnnGm5X8sDPeKPDKDzRLKadN5M432B/X4vkk6M94TfqrN9tnDVN7FQoFrl3TU7JFjhVJvyYRvIB/BvQDny0UCpep/urGNdzi3+u856sy2Ua9CoXCpQjyh5jL2hpbPu47hD+H+yrLXziOc7Ga/DI9rgKncTOYGtKepzwuoFgoFK5FtEdmr5NF9ZN69Mmor0cBxXp8lS/rq1b7x40VqQ0Il375z3A5s96saVNBvewFq98EfuAFrcSDDi7V+RO4nF4nTY0WoX8BPI5LR/9N4L6QtlradOCNwPPAd4HH8nbShOfgEdwU7Y9Tll2k8IkHvS+uZzPW70VcNl/fL7d5C/H2FGT9V+BGmawGT9aHaujzLm8NLcLNftuk8zfv/neBX8LNPPuUbj5uxgt4FjhfZv+1nv23pDX+tAbyP3DZYv9vYhav8Bz927hpiO9LSc8Wz8CJBTXgUU/vI7ovHMP+GnB3vb249QW2p2GLrC/c9M7D5UE3pO2P+EEwQ/0KQd1IoQZA2Rwvqia/hv6vAl+P2PZDgMzbPzKe60VZzbV/pXLGK4QYAv5QSvknNfbTiBvETkkp35+IcpUy3g38vZTyeo393AU8h5sn/lu4dUNvJKCi338T8EHgdwAHt8BO8pNncdNBCLEDGJNSnorQthH451LKr6Sv2cKFrdWQEDzn/kPgHVLKyRTlbAF+SUr5s2nJsLCwSBlRtsV51zioRZdadK+ncd+s85NG/1FlpFnXIEu/zXIc8/WqNxtF2vHmXeOgFl107bu7u0Mr+juOM1wqlTrqZdxVdJi385NG/1FlpFnXoBZZSemm83Fdv1HWRBKvdeaBLOc6Cowy14I0zO3t7YyMjGgnMi0cPHhwDt2yn3wwOjrKnj17qupdKBTo7++vlvrX4T9bTgHf3t7Oc889h/ConesFqjEG6ePz0sX3EyAxXapRgqehq8rvjh8/DhCJDy34fKFQYHBwkKmpKa3flvueT1ff0dExk0WlayuEoL+/X5kmrGpvsibmK1RreWRkhFKpxOjoqLJ9a2sra9asSXxNRQ68Pg3zjRs36OnpYceOHZw8eXIm1TVLjI6O0tLSQk9PD7fccguO43Djxg2klOzfv7+ifVBvP4VSlfrX29tLoVCoeHZ4eHhmzI7j1B1duG6MAwMDmc9PmJ+EvXweFSpf9Mfb19eXiK7Xr1+vKIai8rvm5mZaWlo4dOgQS5cuDZUVfP6OO+6gUChw48YNTpw4odXN973e3l7a2toYHh72E2y0bcPShMvtF2yvSpNta2uLRS1fb1CtZd8vOzvnbuTDfGxoaKjmzWbkwNvQ0MDVq1dZsmQJt9xyy0zeeF9fX+qMwEEsXbq0Iod948aNM2mOQfjOGsy5fvzxxyvavu51r6v6rM9GnPVOMgwqPcv/Eshbl2KxyLFjxxKxmcoXN2/ezLFjx3j44YfnfHHG0bWtrY2+vj42b948p63K7/w1cN9991UEwyDCnlcxIOt0K5VKrFu3rmpbgN27d0ey38aNG7XtAe6+++7Qsc0H6Pzy1KlTM+P3sWfPnjmp/X77ZcuWMTIyUvEXhykW7BmvEIK+vj4GBwe57bbbuHbtGv39/XR1dTE4ODjjgPUy7io6zNv5SaP/qDJu9jNev8JWd3f3jJ93dHRofVq1JgYGBhBCsHbtWtasWZO7r8fFvD3j3b9//5wJvHbtGqdPn6ajo4NLly7FkR0bKl0GBwdZt26d8k8iVfvVq1eHfmv5P6719/dXjHnz5s309fXxyCOPpDhKMwT1HB0dZXJyknXr1mV+1KCbn23btnH48OFU+n/llVdoaWmhr6+P17/+9ZH7CtptaGiI22+/ncOHD1f0o5I7MjLCihUrGBgYqOoPujXU2trK5GTlG4hB3cbHxymVSkxOTlbIUvXd1dU1c6YbRY+urq6qayJ0gHWOoD39mOGf25ZDZaPx8XFeeeUVurq66Orqqk2ZpF/FSPuyr5PVt572dTL7Olk9XvVmI7PGsBmXc2kpbi54plTsCn324GZx/SowUqXtc8BXcOsoXAXeaSDnAPAP3rM/lLcTVdH1zd5/XwA+Xye6fAc3OzDp/ncBS4D/nRqZgst0fQn4dEi7ZqCEmxq+BrjbUM4Pe/4ngJ3A0irth3Brl6wGrgOrQtp+BLgU1eb+Gsatm3EVcPL0lywu3KzSYe/zGwjhjAMagUng7cCbcTnbEkklNi2E3gycAsallMcNn00cUsqnAIQQB4D3VWl+AXhSSimFEIdxv7WiYgj4jnRn45uxlM0IUsp/8j7uxw0Q9aDLPmBFCv1/G0AI8Szu/NbSV7ndRqs0HwKOSSlHgcEY4no8X/pOhLYv437xjwBngbAq7KWyPvdRxeb+GhZCvIJrP5M1MV8xCRwEkFI+UaWtxJ3rQ8A173MiNrIpwxYWFhYZo8H0gZaWliEhhAy7WlpahpJUMorMNOSa6pCm/HrWJwtdqsmI2n8SutbaR72uoSz9N0/Ugy2Md7x5vLqUxesdSeiQ5atl9aRPFrpUkxG1/yR0rbWPel1DWfpvnqgHW4Se8eroaw4ePFhBCf3SSy/hOE6k1Mm4CMptb29n06ZNc2iYhRBSR8EchZoZQDVmlfxCocDY2BgjIyO5pA+r9HnwwQcZHJw9dhRCVHhYGjn3Wehy8ODBOTToUs6lLY/af1DXYrHI1q1b59Cf+33pfCbYR3n6sA/d+lE9H2YvE38O8/Gg/drb27n99ttD52g+12eA8BhWbotCoTAnOw2q299HHBuF7niFEDKYu93R0UFW1NflekippkUXChrmjo4OJTW27r6fj75z504A7bNZjzsMQpjRgl+5coXR0dHYdPXVdNFRZMehKDcdrwndtqndVD4ThRZdeFlsJr4UpkNUqvEw30/CfvMNJjHM1P612KjqWw3B3G3QU19PT0+nRsWto0WHypoLoKbG1t3fsGHDnKpMumdV425paWFycpJisZjKuMNgQgve2dnJ9PS0EQW1CXQU2SpdNm/ezNGjR411CY73ypUrgHl9ARO7qe7rxuuvg/KEFRNfCmsf9PENGzYo78eRqbNfcAc/X6Gykan9VTYqFouxbVR1xxv8d6GhhF6+fDnHjh1jx44dNDU1Jb6j0lGAt7W1odJRNS7d/fJ/B7TP6nQ4evQoDz74YKa7A51N4tKC17suQgj5pS99qcLnFi9eXHVOgzveWum8q62BBx54YKZehIkvmVKK63RLQmagv3m94406f2lTus+BDHnJV8fAWQ1em5pfMvavMJkdHR0V+jU3NyszTQqFQtVMlLCslazHHWKPZTp91q9fn2rGjcn8JKmLToZq/sP6N9VV5zPV4Ms28SVTHVT3db6flP3m22USw3S2iBI3TPUyXWCRKKGTniyTFD4MaJh1/64ad5aU31Xm4AHgbKFQmKqmT3Nz82u4zLGJ0NXXMj++beLqUigUriTRf6261roGTJ838duwz0nTyM/Xy7PFZNKxxFiPGgawApjAZerdh5dKm/ZkAf8LeA8uDfV/ydpBgE8AfwC8DTcTLhP5uOfxn8el7H5c5VDB/wfW46ZK7wceSFk/nxJ7TZn854GnkrAPLnO1DI4XuAh8L0Z/nZ7/NgFPA4+ZziVuSukgsBX4I+A/Re3Ds9UHA/O107u/OcV5+gXgc8AOT/fGmzHAhoz/S7jp0SuCvuR93uLNwa+lqkcNA/jd8oWQkdGaPKPsznHiJPDJHOS+wZN9j+FzzcAwEem96/XyxlFRS8ALHLfE6O+PavVfYK83J473ZRy5P2CJyf0U7OmvpTfmPbdZXsA7qFJvBXg/8GCaesROGRZCNAPrZATK6CQhhLhL5lgnQgixDfi+TJC63SJ7CCFagC4pZWwaEeH+GrtNSvmCEKIBuENK+UJiSqYMIcSdwIsybhCwiA1bq8HCwsIiYxjXaijHQsw5T7JuRF5jiSvXdOwmcmqxRZrjiWv/etAp77WSNZIeb5r2i7zj1aXeVXte1PAeYB4yk5AfVQeheMcwTj+miCs3ynPlz5rIqcUWUZ51HEeZ9mkiU+UPYemkadk4qk/o+rpZadyTXk9prs/I9XhLpVKHKvVOR0F99erVmusXlEqlDlW6poome2hoiOnp6URrRejkg5oeO44OOsppSI4KXQWdDVtbW6uSY+oo0aWUVWnH/boenZ2dFXKCOhWLRc6cOUOpVKpq03379rFq1SoWL16spHu/evWqMr02qN/y5cs5dOgQzc3NFTJ1a0CXZqqy8cDAQNW1obLD+fPnGR4eNl5TKv+6mWncVf42MTHB5cuXY8WGYH/l81zL+jQ6amhsbOTixYsIIWbShycmJhgbG6OnpwfHcejt7QWgWCyGfqtGVrChYUamD59PrKenh7Nnz9LY2IgQglKppKR3T1q+T/1cPu7h4WGmp6eZnp7m5MmTkfsP9nPy5ElGR0fp6+vj7NmziY6lHGE2DONo88f+6quvztF5aGiIc+fOVaTpquzkOM5MUAzTaWpqasbRn3766dDxTExM8PLLL8/I8dOJh4aGZuwYxX9PnTo1k8qsoopX9RH0ET/NVGXjtra2qkVXVHaYmppi6dKlHDx4MNQOKrsE/Us1Dr9QkInv1iNU/nb58mUAzp07V3N/V65coVQq0dfXVxPlvREDhYr6WUcrfuTIEe66667YioXJ1NFkHz16dKbQTVKISo/t04vv3LmzZnpxn3K6VgrpMKhs6NdQCLOhjva6WCxy+vRpbr/99qrj8+nTgxTlb3vb2zhw4ABXrlzh1ltvreg7DDo/PHbsGGvXrgXM/Le3t7dCP10fOkp0lY1XrVrFxMREaJ2KMP/WydLBhPYdYPv27Ub91xt0/nb8+PGKL/pa+puYmKjwdRNEPuMVQsgg9bNH91ztudhnlHnIDMo3occ21cGe8WZ3xisU1OWmvqTzx6CP1OKnWZzxqmwxMDCA4zisXLly3tK435RnvI7jDHd3d1ec/eiooh3HYc2aNab6xJY5MjLCsmXLlH8e1iJ/7969keSPj49z6623RqL5rtbX4OAgnZ2diY4lqtytW7fS09Nj9JxPO75y5coK2usgpfbp06fZvHkzp0+fjkSfPjAwQLFYZPHixaHjUclZvXo1ra2tdHV10dzcrPwLQqdfX19fxTyq/LG5uVlJoa4bz5kzZ3Ach9WrV2vHorOD4ziMj4+H2iHK+NasWXPT0rirKNy3bdvGiy++GGvHq5qLy5cvc/36dVauXBlf0VqyL+q1bkOaNRPyohevBxuajj0tivIsxxPX/vWgU95rJesr6fGmab9EBgz8KbOUyevxjjDSvDw5Epf2uo0qNNkpyBe4VPf/AjdttauGvv41cNX7vBZoyGgM78WlDBdAF7Ao4nOLgBu49Sre5H1uDmn/d8Apf96q9N3uzevtwIeA6Yg6vQd4Xdn/NwC/HsUXgc8CF6LoZ2jfB4B3Be59COiM8Oy7PP8Sno831aDHCeAbSY+vHq8Qm3fU0KfAzdIFuAT8Sa16mtK763AEjxJbSln7qwzR8CrwJG7Afy0jmTOQUkohxJO4hXJew6Xhjote4C+9fs1/eo2PQeBL0vUoE/1fwy1+c9D7fACX/lqHZ5il1K7mH1O4RX3OAv8TeGcUhaSUXwz8/w3g96M8i1vM50JE/SJDSvld4LuBe58SHjy763Ae+IrX5nxIuyh4wruyXJ+5QGfzGvuUwID3v58Dai5ZYFOGLSxyQKRfEy1uWtSUMlwOmz68sNKH85CTdAqyafskUnz99sCNtHRKy/71grg2T9MPTJHYjleIhUdZHUV+VB3yGktWcpOQY9KH6dzE1c/0uaTHEHVu8l4rSWK+2DwMsc54o9K+F4tFDh8+jBCi5vRhE6r5WlIEk5A/MOAeB+nkR+2rvb2d5557Dsdxah5LNarxIG16ebptc3Mz3i5tDmqlF5dyLj07MCMnKq16WFqxru1b3/pWpUwdZXuU9PeDBw+yYsUKZcpyNTs8+uijMz4TVSdQ+5cJpbzvX0msz6xhuu4OHjxIoVBgzZo1c9r7Ph7Wd5if+jCtbxFrxyuEmjI5CuV13G+KPGQG5ceh+VbpoBtLmvTxKv1N5EalvU6KXlxHXR7VRkKoKed1MuPa398hDQ8Pa58N7r6CcsLsa6pTrfM8X3a8JuteZXNde11b3Rz5NS527txpZLvYbzWoKJN1lNdjY2M4jhNX1AxUVPNhNNvT09M1yyyHKc03oH1RXjUWFeW08OonLF++PHH9w6iufbn+S+JRaa9N5aj68F/uj2ojf647OuZu9HRzA9Epv1taWhgaGmLVqlVauz711FNGPhiUY2qzajqZ9OXr6KdVzxeo5vbKlSuMjo5yzz33VLTX2XFycpJisVi1LajtumHDhlg1aWIH3scff7zinkoxv4bB/fffH1fUDHR1E1TG6Ovr44EHHqhZZhz5mzdv5siRI+zevXtOcZ1qfakCULFY5MSJE2zatCkV/cPknjp1KrTOge6+iRzTvnW6qupE6OYG1P6r6jtKXr5KzsaNGzl9+rTyz17VF4qJzarpZNqXqm5GvUNl887OTiYmJmhsbKxorxv76dOnK7L4TP00Tn2LWEcNTU1Nl65du7YseD/NQ+k8ZCYhX6VDHmMJO/urJrepqYlr1ypf0y0UChX3TevTdnZ2MjxcmaGq6juKrlF+JNHJzOvHtbD6uKY61TLP8+moIesf16rVMG5ubv5BqVSKnkMsk8kWyZT2HTdbashxnFeqyWxubr4OfBoFUWIWY44ybnKij/fG8ANTueRAL27qYyZzU4v/mj5nYoek1lRe/pXWZToWk/YmNtf5aqS1l7RRgF8E/gmX9v2beOmvpopp+m4Cvo2byfMGnZOVfwaWAH8NnAF+PC1nAD4J/BDwYeCbpmPGfadaAm8ufxZ4xLuvTcmtUe9zQL/KhsA/AtcSlPVZ3Ew/f25uAV4Bdhn2816gBzdV+x+BxTp7e3Y9CewGPgL827C5AX4Z+DrQ6vlxJP/FTWF/FZcN+a+B/1BFzt8C/xbYhZs1WAhpuwg3i68ZNwPwQ6b+VdbXXwC/4/nV5+P2Uy8Xbjr6ZuC/J2zzh704I4C/AbqTtFUahugFelIy8nbclNJths8J4DvA32bgCI8DMuazyroCuvsJ6duBpkaDZ7fYNShS1PlpvNoKEdr6tR+6I7bvA74bQ6df9+cd+BpwpUp7Cfwb3I2BBO6KKOdFXGbguLaTwEfznsMUfCJRm3uBvJSWvomnDAshHNzCJguW/lwIcYuU8tUE+xMwu6oXOoQQBQApZVh9iPL2kecjrv96c9QipZws/xxFJ0P9GoGClFJPExL+fKK+WS9I2uaenRdJKfVUITXA1mqwsLCwyBiJ1WooRz3mRteiY1LP1uNzUeyb5nxWa5/UHJjIybOuQdqyk6wvkiXy0Lsu6N11iuleXTlw4EBoqqMIvL4RlnLZ3d2NTKlGQTB9s5wxd8OGDUq5Qgh54MCBiuduv/12BgcHQ+UGnysf5/r167WvLAXtWSgU6O/vp1gsMjo6qsyc0Y0xisxq49X1YdI2bGx++ufrX/967etpQTmFQoEdO3bMSe0Ma797924tAWJQJyEEg4ODNDQ08NBDDynp4nWv0pne9+esPMU1TFcfwbRV3fr0+w9LT6/mE1mj3Jej2CWpuThw4MAceT6LekdHB93d3bHtVFPgFaL29ETfoFFTLpNCLXKF0KcVVqHNjp2WmlY6a9g448gXItl0ThGSTquSE9Y+6VRdk3Rpk5Rr1ZzpdA36V/k8qtbn3r17lf2HzVE9QOfLYXMY1eZJpKibjqfmQuim6YmlUqkiU8Q05TIp6OT6KZlhMEl/LRaLvPDCC9rndKmL1eTp7Gkyxqg8VCbyq6VRV+s7mPqp8zGVnLD2tabqXr16dWZ3CGbp0iYp16o50/WxcePGOZT0QajS3Kutt2Dqdb3AxC5h93WZaVHTyJOwU82B1zQ98fTp0xXVgMIcKskKY0GEpTg//PDDoc8GJ8lPRdXZ47777gPMUhfLoXvu6NGjocSJYbZ9+OGHI1PRm6Sbhtl1x44dkfreunUrJ0+eBPQ21S2sqD5p0tanfT969OhMqq5JurTJfdNxhaXjm6bZP/jgg9o097xhahfT+1HTyHUp6iao+aihVmpr/0+IKG1jK6rRPa5c3bNCQZt95swZCoUCa9euzZzyO8pzumfjyjfVtVp7/0/6qD6mmoOBgQEefvjhivamfVeTE0b1rrsflXJep+vAwACNjY10dXVV0LKr1qd/lFEN9XrUoLhfs83PnDnDnj17Is9FUH7mRw06+nPQU1Q3NDRU0L6H0VnXRKFcBSq5/f39dHV1Vf2RLEgj/corr1SlzdbJjEJhrnrOP38K01VH475u3TrOnDkTmYpeRZut60Ml89KlS7S3t/PSSy9V7bt87k3p07u6urRzEJSzevVqbd/BtpcvX6ZQKLB48WItXbxO17D7Kl1V4wrT1UeQll23PnWU5YVCgUuXLkX2iawghHgX6H0wCZubzMX4+Picyn2xIFPIysiK1jsrHZN6th6fi2LfNOezWvuk5sBETp606GnLTsonsriAxcAfAuccx6lab8HT+zXgR0kg27Pu6d1DDCdw8+mFp+jjVdo3ev/9OhFTQhPS05f7l8BoxGf+GdBa3gfw9ojPfh94zvt8DfjtCM8UgLcF7m0B7ozwbItn/z3eXMSij8d977sBWOH1p5UNfAKY9H0gQr8Sl6J9p/d5cUSdTgMHvc/XgV+LONefAqaqtB0D/rz8uQx98l96dphZQwn3/xbcTC9j/83QBge99RGZmh14h2e3xMaCm6Lem6QfJEXvroR0NX0NQAjxH3ELm4S192naP4Yb2DJBmdw/wM3Vj/LMPyr6+FpEkf8FN+ce3LF+K4K8a8A/BO6djCivBPw58B1vTmTE54I63AAQQlwC/j/cAjs6fA0Y8p57LaQdUsobQog/wy0Ec9XTNWpa66eBI97n38OjMQ+R5evySdy6H2H4U9wv46pjSAHfBT5evoaShJTyG4H/N/HfrPB23CJNE1EfkFJ+VQixFrcITlL4Mzx/TMoPbMqwRaoQwtaZsLCoQFLb8ZvxXDfrMZmev+V59prUePI8K70ZxhAmux7XZB72zMKXTXXOhd59vrxClvWYTF//yvM1r2B7zb/nMs9RZUeRX+9jCJNdj2syD3tm4cumOid6xnvw4EGklGzcuFFbv0CIWdrqxsZG1q1bp82z99uWw5RGWaVjudxisciWLVu4cOGCUu6+fftoaWnR1h0IItj+kUceUY4/jCLHRKaqbRgVdbC9X5siih5h86kbz759+2hqaqK7u7vqPIfZBMBxnBulUqmisFM1W0aRX62PxYsXz6nbcPHiRV555ZXEaNF1dRWC/mpCOe/rHtWXVGuyv7+f6enpROnfTddUUjLL59APolLKOa+RhdWfUcWOF198MXL2ZzkSDbyjo6O0tLTQ09PDLbfcguM4DA4OVuRM7927t6Ktn44XIR+9pnxGlY4XLlzQ5nVPTExw48YNenp65izYgYGBioX61FNPVbRXjV+XS753715lH+UyS6W5ZVhVbVV21PV98uRJbcBRtR0cHDTKdZ+YmKC1tbWqfmF59GVz3xDHlir5JnUWfDsMDw/P9DE9PY0QQvlechyUSqUOlU4qf21ra2N0dDT0S8qHif+q1qRfDOjZZ59NZJymOiUts3wOfVnlc14qlTp0fqCbi2rlBVRINPC+7W1vU95X5YtHbeunmw4ODmrz0dPQ0U9HfPvb3z6nXdhL07pdQdRccl0fYTJ1+qXZt0mue1T9wvLo29raZgJcUrZU6ZqED9QCVUqzyl9N5JvoXqusNHTKQ6bOD5K0T6KB98CBA3MU9hfk2rVrEULMZH7o2gO89tprMztFv/2xY8coFou8/HLtb4jodFTJ1bX3c7X9+gth/Yf1rbKLSt7y5cvp7+9n27ZtFXn0JjbX9a2roRC1b7+EY1T7hfWhun/hwoUZmnkTW4bJV/WRlA/ERdQ5a2trY2BggLvvvrtqnya6m/pHXOjG1NfXF4sqvRaZR48eZdeuXXPamviBPxemSDTwqhRevXp1aCpeuaPFSYtMQseuri6tXFX7F154QflFoBrTqlWrjFIXVfLOnTvHkiVLeOaZZyrSOVXtV61aFbnvM2fO0N3dzXPPPVfRPhgIhoaGWLdunVHKpYl+uj58OI5zY+/evcoz3qg+NjAwoEwrDktNVn0ZTE1NJVrFy3Gc4e7u7ooOVfY7f/48hUIh0kbExH9VbQ8dOkRHRwfPPPNMYmMN2vPSpUs0NTUxOjqaWoGeoMzTp0/T0dFBQ0MDixbNhsGwMghhc2EMk1cgwq56fHWlFh3zGJN9nSzbub4ZxmBfJ8tGZrU+mpubh010StxZgN9nlt58BHhTSFuf3nsd8JPAD6fhwAq5zcAlYBvwY8C7q7T/f4Ev4qa2TgD3hrRdiZsp1gZ8CNgdQ79GYBCXkvytwE8mZXOvzUeBjcBvAPuqtP1z3Cy1ZtxMr9sMx/IBX7eye88RSH9Oca4X4dJ0PwT8BPC9mP18F/g5XKbrHwDNWejvyX4H8LL3+Sng/zJ8/jO4tO6LcDOwwth1V3n+uwT4BWBXCuN5N16ad9m9J4EfT9GGfwd8uOz/NwGnY/TzOeC/4abwTwFbY+mTwgAPlwWBS8AnQtre631jOGkZXCO325O7NGL7XuAvvc+TwK+EtH2L13esegheHz799JqkbR547meBq1XanAf+1Pt8HfhXWc5VAnO93LPlKmCv99m47oH33Ltwv1AlsDbDMXwKGPI+P4Wb+m3yfD/w37zPpfIApGj7z+PaaCFcuGnyn/E+TwMfitOPTRm2sLCwyBipsAxbWFhYWOhRF4E3LsV3mjJrkZtE31n1kYR9k6ZaT2vOLaIhD//NWmbePpgKvbsphTJUUm9HoVmvVU8pK2nlgym+ccekGw9QQXGu0y9IMd7e3s6mTZvmpDdH0cNRUKe/+93vrqBBjzNv1eQAFXThQgj5/PPPz7QtFoscPnwYx3GU7U2gsmUU/ctT0U39WtVHLahlDOBmXwX/LY7/lq8LKeem9VabHyFm6diDPuyvg+7u7jk+YbJmdDKDflie1lveR7l+unFu2bIl1nqI4gep0bubUitXo/iuJfAK4XJPBXWRMh26aFNaaJUd9+7dq6Uv19kwah+6fkyor8+fP48QglKpxM6dO7VydOOdnJzUtg22N4HOlmGp6K2trWzfvj10PiKmNNfkp+VjiJrSHJQPZO6/ujGo1peuDyGETEJm1D6i6mdiS38udu7cWdUPUqN3N6VWrkbxXStqpdE2GZNqPOfPn2dsbIxly5YpHUKV8qqjL9fZMGof/k5XlTar61vHutvb2xsqR7czKE/YCAZBXTCOCl36cHnmUZDhuVofUVOak0LUlGZVOn2a/usY8CCG0ciroKNSL5VKrFq1KpJMk3UXpp+f1WdiS38uoqDmHa/qee9bxej+l770pYpUvP7+frZv357IjjcoVwjB008/XZEC6P35U9OYdH3rxqTTT0pZkaa4d+/emvVYvnw5ixcvVrY3GXs1OcVikVOnTnH//fdXjFdnn9OnT1e0N0GYLas8FzofUe2Q1I437hiA1Py3PH24qamp6u7TpI+w9r29vWzfvp2GhoZYMlXrzkC/yLYM/Hu4H5S/W2Z66bI5mpubldkdhUJBm/kRBu/fY+tZKBSURHkqrF+/3kh33f1qKB9TEvrpbK5DR0dHzWOMO17T9iaXypY625Rf5ZlLuvmoZoekMq5qGYNuTabpv6orD58w6SNK2zhxLKof1OwkisEXo372/6tz9KQduly+SRphmO6qz7WmKCahn5TS/7El0oI1HWMt460230nOuYk/ptlHnmPI2n8938vcJ7JIkTaxZeicpuUsMZyrEbgCdACjwEcycOhJ4EC50YBOz/A/mUD/rbgpxrfiZhy9Nc6YgBPAfbgkmb8Ss48v4TLXfgT4fBq2xWXEHcFNAf8i8IEwOd54XgIeA46nPd/2Mp7PWz3/bcUlIX08zhzhlgX4APBZ4Ber+MTP4ZJL/hQeC3QMeW/CzbJsAsaBZVVkjgC/DvwJ8LE4Mo1tm/fklg3+w1T5UyIFmT/iT0qU+zH6/wN/TMDzwGCMPh7zvgiagf8Ux0bewpG4tR/e7n1elII9P+D1LYC/ASYjPjdDP5/l/Nur6rx8Isk1icsIfaNKm2m89PyEZF4DPhux7UezikGp0rsb4su436qZQUr5Nyb3Y+BzuLtVgH8FbI3Rx3dxd7lXhRAfAyp/gq+OKeC3gWdwg+K/k1Jej9FPNXwd+AUppRRCfAR4c5SHpJRTQohfAQ6loJNFfHwGtw5IUvht4FiVNh8mWZr5H8f9qyoKPoG7Q04dtlaDhYWFRcaoi5RhH0mn8dXSXx5pzDczrD3nJ5JOw40y12ml/maVQh8JeZ0f6X5VrAYMzmBq6a/as8HnTF+tK7+i/NJarZ8oRcxN+og7h2EyVNC9HhdXJ3vltybD2qrm2dRXTGTq/MpEvzT9MLejBl1a5JNPPjmHhrlQKDA0NMT09LRxDr8QQgb783O3IbwmgBBCfvvb366gctY9JwzTp1Wppro+wtJ2VemqKtua9hHVviZpxwcOHKigD1+9enUmabgW1RG2JsPo2MuTEqSUFfTt7e3ttLa2GjE7B9ft0qVLGR0dRUo5Q+fkyzxw4ABSSjZu3DijX3d3tzKF3kS/NP0w18AblC2E4Ktf/Sqtra2USqU5NMzT09N0dHSwZcsWo8Cr669UKpVnqikD77e+9S1KpdIc+nk/3TGYjx0326msjdD1EaWfPDKvTDKshBB87Wtfo6WlZY5N/ZoZSelkER8ma9JPH169ejXr1q2bs3EYHx+vaH/vvfdWzHOYr+hkAnR2drJ169YZmVH9Sni1F6Lqp9D15gi8wZQ9XTps4DmjwBu3v2rPqna8UqpTfHWpiYODg2zdurUi8KrYTLu7uyOnVats6/cRpssdd9xhHHhVc2iaip2kThbxUeuarLZxCPqvzh91vmIiU+VXYWNR6adao6FKGSDX18mi0lnXQqWt6m/ZsmWMjIywadMm42f9+gMqqFhtQc8cPDY2Fomp+MyZM0AlJfmLL76IEELJNhu07ejoqPL++Pj4HPp0U6jm0IQeOw2dLOIj6ppcvnw5R44cYffu3RV96OZZ5RMmvqJbtzp5wb7DxqLST7dGk0BugdeEzlpHRx0Fqv6OHz/OokWLZsro6aCihJ6amqKzs7LUpo4WOow2vPzZsD78fqpQnw+Xf1bZ1qSPKFDJCRuvai5Wr16dqE4W8aHzGx29fUNDw0xhHh+qjcPAwIBynsN8RbX2Ll++rKyMpvKrrq4uZd86Cvs1a9Zk64dJ/lJX65U09XMt/VV71v7anuzcmtJj26s+5q18LURpG2XtpFVzISn9krhyn1ilUvBBvPRa73NLDX1tB/6WMtZU4OPAT0R41q+1cBfwr4Ezedtmvl/A3+PWcWjArZXxaN462SvSvH0MeMH7fAr4tSrt3wOsB34CGIgpsxe3dsM2XFr6W0La/jzQ730+DHw8pG0D8APgh4E7gbdnbc96ShkuxwZgCEBK+elaOpJSHsWl5S6/90sRH1+MO0l9wDLcIjoWtWEV8ISU8oYQ4iKwCXg6Z50sqmMd4J/1vYy7RrWQUn4RQAjxAtAW+subHkXclPsB3FT3JbgBWIUNgM+JdQ4I+4FgEXAL8KKUsh94wVCvmmFThi0sLCwyRl2lDJcjaZZSy3JrYZE86ioN1xB5prHX7Y7X9B1ck/dua3m/18LCYhZRTxDqcT2ZvqufJOrijFdHpx2khi4UCpw7d45SqcSePXsq+jl06JA2Nbha38VikW3bts0hqxNCSFNqcItZ5E2TbhEPceZNtZ62bt06Q6wK7noqf6Z8nk1lqu6bUtir9G5qaqK/v5+ODuVbnYmhLna8QpMjniRleLCtigZaaCjPdfUTWlpamJyc5L777qu7b/N6gJ9CGrSdzqY+s3QUemyL9BA2b6r1IaWaJl21nsLqi0SVqas7Elb7QXc/jA7+pt/xgprOWkUZHkb7HqQMD2urooEGNdW1KTW4xSxM6LE7OzuZnp7OWWMLMKOC19Gkq9r72Z8vvFD5IkFUmX6igypmmFLb6yjlGxrS/fmrbna8QT10OfxtbW0MDAxw9913R6YM7+/v53Wve13Vtqoc8WqFZcra2B1aAGF59HmdrVlUh8m8+fd09UVq/d0lrJBO1LUadl9Vn6G3t5e7776bxsbG1PywLgJvU1PTpWvXri0L3s/6x7XOzk6Gh+dmBtoz3vjQndsVCoWZnHwVrD3zhem86dadaj2Vo3yedTFAJ1N1X7dWw/wttw1A1hkbUS5SoAyPUig82J6cab1vxktlO2vP+r9082aShmsyz6Zrz+Sz/1+TmJH0VRc73jAIId4I/HvgYeAisF1KOSiEKEopryjaH8ZNH3wr0Cql/MWQtj8JvBP4aeA8sEJKWdK1t7Cw0EMI8RngKG4G2c9LKV8/H9aSEOIo8DPA7wHHpZQfSVvv+RB4T+LWalgnhHgN+IqU8j2atnfjTnw7riH/gwz5U0EI8QrQI6V81HvV5aNSyt9JfhQWFjc3hFum7AbwU8BB3HoOq6SUdZc4UQ4hxH247NZFKeVoVnLr5q2GELwfGPU+P4JXw0GD48DjUsqLQog/ZpZaXYd3Mpun/Wbg+Rr0tLBYsJBSSiHEjwJ/I906HO+p96Dr4QhuzBjNUmjd73gtLCwsbjbUba0GCwsLiyyQR+2Wugq8OgM4jqM0hsl90z7qubiHhUXeMF2r9bKeVHqXSqWOam8hqF6vqwV1ddRgmmKqSie8cuUKW7durTmd0KavWljoYZrimxZNuil05QmkdGnfyynlFy1axLlz5+js7NSykcdFXe14wU3tu3jx4gyXU3nKn+p+Y2PjzP0TJ07M8KiZ9KG639nZSWtraxZDtrCYl4i6Jv2COS+99FKe6s4gqB+4ac8TExOMjY3R09OD4ziMjIxQKpUYGkp+k153O16VPnFSAYP3TfsI/Lvd8VpYlGG+poOblCdYvnw5x44d44EHHqBQKCSqd929TuazlAbpnnX3+/v759wbHx9X3jftQwjB4sWLc7CAhcX8QNS1NzAwgOM4SobgPKCKDSqaeoBdu3alokNd7XiTqMmpux+nVifYugEWFirM11rLOr337dtXsSkbGBigoaGBNWvWsGbNmkR3vHUVeC0sLCyyhi4YlyPpLwwbeC0sLCyYqQvzDaAZ2AGcSqteQ92d8VpYWFjkBIFbu+UG8Fy1xjUJsjteCwsLi2xRd+/xWlhYWOSFrNKH7Y7XwsLCwkM1JhuvTc1vONgzXgsLiwUJ3dsMQcr39vZ2RkZGAFi/fn0isu2O18LCYkFCV7chjPLde87ueC0sLCziQkVXH0b5vmLFikTk2h2vhYXFgoRp3Ybe3l62b99OQ0NDzTteG3gtLCwWJHSU8ln8uGZfJ7OwsFiQmJ6eXi6lFP4FLHMcZ1gIQdjlOM5wrbJt4LWwsLAApJRXpqamOr0gfCcwghsjDwF3+cE5iZoN9qjBwsLCIgAhxF8B75VSprI5tYHXwsLCIgAhxFJgiZTyXCr928BrYWFhkS3sGa+FhYWFAmnWbbA7XgsLiwUPXfpwWq+W2cBrYWGx4KFLH37yySdpaWlh7dq1yroNcQOvTRm2sLCwAC5evDiTreZT1U9MTHDjxg16enrYsWMHJ0+eZGxsrGZZdsdrYWGx4GGaPnz8+HHuvfdeHMexRw0WFhYWcSCEkH19fXNYhj1m4WrP2aMGCwsLizhwHGe4u7u74se1/fv3V9C+nzlzhs7OTlpbW2PLszteCwsLCwXSpH237/FaWFhYKOAF1HuAHw0U0/lZYK2UUsSt22B3vBYWFhYZw+54LSwsLDKGDbwWFhYLGqapwdXaR0kjtkcNFhYWCxqmlO7V2kd5xcy+TmZhYbHgEaR0LxQKDA0NMT09zUMPPWTUPgrsjtfCwmJBQwghL1++jOM4XLt2rSqle7X2dsdrYWFhEQHHjh2bk6VWTusetf2VK1cYHR2NJM/+uGZhYbHg0dDQwMWLFxHC3ahOTU2xceNGFi1apDxqULXv7OykpaUlkjx71GBhYbGgkcePa3bHa2FhsaBhSuleKBQu10r/bne8FhYWFoAQohM4A7QDnwIuSyk/IoQoSimvKNr/NfA94B+AbwJrgFZV2yDsjtfCwsLCxeNAi5TyVaAZ+BmAkED6HuA14CSwArg3StAFu+O1sLCwmIEQolVKOSncX81apJST1doGP0eSYwOvhYWFRbawRw0WFhYWGcMGXgsLiwUJVbEbx3GUhW9M71crmGOPGiwsLBYkdJTu+/fvr8hKC7sf7MPPeLvnnnu0ZJh2x2thYbFg0djYOJOBduLECUCdlRZ2P9hHsVhk69atvPTSS1q5dsdrYWGxIKGjdFfFRNP7gX+v2PHaIjkWFhYLFv39/XMYhEHNLBx2P9jHwMAAjuOwcuVKrVy747WwsFiQULEINzc3KyuSmd73oWMhtoHXwsLCImPYH9csLCwsMoYNvBYWFhYZwwZeCwsLi4xhA6+FhYVFxrCB18LCwiJj2MBrYWFhkTFs4LWwsLDIGDbwWlhYWGSM/x8dWFYlilrT9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(entropy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you can see, our decision tree is huge, and this can cause overfitting. To reduce overfitting we can use pruning \n",
    "methods.\n",
    "\n",
    "In decision trees, one method of pre-pruning is early stopping. We can limit the max depth of the tree and limit \n",
    "overfitting. Let's limit our tree to 8 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       167\n",
      "           1       0.76      0.63      0.69       101\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.78      0.76      0.76       268\n",
      "weighted avg       0.78      0.79      0.78       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entropy_tree_lim_eight = DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=42)\n",
    "entropy_tree_lim_eight.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_lim_eight.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see a performance improvement after the pre-pruning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Hyperparameter tuning\n",
    "\n",
    "To improve our model performance, we can do two things, feature engineering and hyperparameter tuning. We already did\n",
    "feature engineering to improve the quality of our data. Now it is time for hyperparameter tuning. Hyperparamteres are \n",
    "the small properties in machine learning algorithms that we can use to optimize the model. There is no \n",
    "algorithmic method to do this other than trial and error.\n",
    "\n",
    "What are the hyperparameters in \n",
    "[DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)?\n",
    "* Almost all input parameters of the model definition interface are hyperparameters.\n",
    " \n",
    "Let's create and train few models with different sets of values for parameters. I chose following parameters, \n",
    "- criterion\n",
    "- max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       167\n",
      "           1       0.78      0.59      0.67       101\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.78      0.75      0.76       268\n",
      "weighted avg       0.78      0.78      0.78       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['entropy', '5']\n",
    "entropy_tree_ent_five = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
    "entropy_tree_ent_five.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_ent_five.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       167\n",
      "           1       0.72      0.57      0.64       101\n",
      "\n",
      "    accuracy                           0.76       268\n",
      "   macro avg       0.75      0.72      0.73       268\n",
      "weighted avg       0.75      0.76      0.75       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['entropy', '7']\n",
    "entropy_tree_ent_seven = DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=42)\n",
    "entropy_tree_ent_seven.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_ent_seven.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       167\n",
      "           1       0.72      0.61      0.66       101\n",
      "\n",
      "    accuracy                           0.76       268\n",
      "   macro avg       0.75      0.74      0.74       268\n",
      "weighted avg       0.76      0.76      0.76       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['entropy', '12']\n",
    "entropy_tree_ent_twelve = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
    "entropy_tree_ent_twelve.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_ent_twelve.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       167\n",
      "           1       0.79      0.57      0.67       101\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.79      0.74      0.75       268\n",
      "weighted avg       0.79      0.78      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '5']\n",
    "entropy_tree_gini_five = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=42)\n",
    "entropy_tree_gini_five.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_five.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       167\n",
      "           1       0.74      0.58      0.65       101\n",
      "\n",
      "    accuracy                           0.76       268\n",
      "   macro avg       0.76      0.73      0.74       268\n",
      "weighted avg       0.76      0.76      0.76       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '7']\n",
    "entropy_tree_gini_seven = DecisionTreeClassifier(criterion='gini', max_depth=7, random_state=42)\n",
    "entropy_tree_gini_seven.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_seven.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       167\n",
      "           1       0.74      0.71      0.73       101\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.79      0.78      0.78       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '8']\n",
    "entropy_tree_gini_eight = DecisionTreeClassifier(criterion='gini', max_depth=8, random_state=42)\n",
    "entropy_tree_gini_eight.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_eight.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       167\n",
      "           1       0.74      0.61      0.67       101\n",
      "\n",
      "    accuracy                           0.77       268\n",
      "   macro avg       0.76      0.74      0.75       268\n",
      "weighted avg       0.77      0.77      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ['gini', '12']\n",
    "entropy_tree_gini_twelve = DecisionTreeClassifier(criterion='gini', max_depth=12, random_state=42)\n",
    "entropy_tree_gini_twelve.fit(X_train, y_train)\n",
    "y_pred = entropy_tree_gini_twelve.predict(X_valid)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From these results we can pick ['gini', '8'] as the best performing model in validation stage.\n",
    "\n",
    "Now let's use the test dataset to find how good our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       266\n",
      "           1       0.71      0.78      0.74       152\n",
      "\n",
      "    accuracy                           0.80       418\n",
      "   macro avg       0.79      0.80      0.79       418\n",
      "weighted avg       0.81      0.80      0.81       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =  entropy_tree_gini_eight.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task\n",
    "\n",
    "Use your cleaned dataset from last week,\n",
    "- Complete all the features. \n",
    "- Try to figure out which variables are useful and which are not.\n",
    "- Create few models with different feature sets and evaluate them.\n",
    "- Tune the parameters of the models and figure out which values give you the best performance.\n",
    "- Finally, after deciding the best model, use the test set to measure the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
