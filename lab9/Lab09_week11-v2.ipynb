{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 09 - Ensembles and Recommender systems\n",
    "This week we are exploring on ensemble methods in sci-kit learn and how to create a recommender system using what\n",
    "you learned in the class. Let's import necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances, classification_report, plot_roc_curve\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import breast cancer dataset. This dataset consists of features of the images taken from fine needle aspirate (FNA) of a\n",
    "breast mass. As the target feature we have to predict whether the mass is benign or malignant. You can find more\n",
    "information on the dataset [here](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset).\n",
    "\n",
    "This dataset is already cleaned and encoded. So in the target feature  (diagnosis) encoding is follows:\n",
    "* 1 - Benign\n",
    "* 0 - Malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0        17.99         10.38          122.80     1001.0          0.11840   \n1        20.57         17.77          132.90     1326.0          0.08474   \n2        19.69         21.25          130.00     1203.0          0.10960   \n3        11.42         20.38           77.58      386.1          0.14250   \n4        20.29         14.34          135.10     1297.0          0.10030   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0           0.27760          0.3001              0.14710         0.2419   \n1           0.07864          0.0869              0.07017         0.1812   \n2           0.15990          0.1974              0.12790         0.2069   \n3           0.28390          0.2414              0.10520         0.2597   \n4           0.13280          0.1980              0.10430         0.1809   \n\n   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n0                 0.07871  ...         25.38          17.33           184.60   \n1                 0.05667  ...         24.99          23.41           158.80   \n2                 0.05999  ...         23.57          25.53           152.50   \n3                 0.09744  ...         14.91          26.50            98.87   \n4                 0.05883  ...         22.54          16.67           152.20   \n\n   worst area  worst smoothness  worst compactness  worst concavity  \\\n0      2019.0            0.1622             0.6656           0.7119   \n1      1956.0            0.1238             0.1866           0.2416   \n2      1709.0            0.1444             0.4245           0.4504   \n3       567.7            0.2098             0.8663           0.6869   \n4      1575.0            0.1374             0.2050           0.4000   \n\n   worst concave points  worst symmetry  worst fractal dimension  \n0                0.2654          0.4601                  0.11890  \n1                0.1860          0.2750                  0.08902  \n2                0.2430          0.3613                  0.08758  \n3                0.2575          0.6638                  0.17300  \n4                0.1625          0.2364                  0.07678  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.DataFrame(data.target, columns=['target'])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "target\n1         357\n0         212\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good to normalize data before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0    -0.634369     -1.602614       -0.573893  -0.706375        -0.602063   \n1    -0.390155     -1.102783       -0.434304  -0.430659        -1.209809   \n2    -0.473453     -0.867409       -0.474384  -0.535007        -0.760951   \n3    -1.256263     -0.926253       -1.198867  -1.228029        -0.166928   \n4    -0.416659     -1.334775       -0.403898  -0.455261        -0.928867   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0          0.062874       -0.009837            -0.024047      -0.386483   \n1         -1.157665       -1.008900            -0.788759      -0.999615   \n2         -0.659168       -0.491093            -0.214902      -0.740019   \n3          0.101521       -0.284908            -0.440548      -0.206685   \n4         -0.825416       -0.488282            -0.449494      -1.002645   \n\n   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n0               -0.329722  ...     -0.351774      -1.444948        -0.229655   \n1               -1.258113  ...     -0.379523      -1.120854        -0.486640   \n2               -1.118265  ...     -0.480554      -1.007848        -0.549392   \n3                0.459241  ...     -1.096705      -0.956142        -1.083582   \n4               -1.167128  ...     -0.553838      -1.480129        -0.552380   \n\n   worst area  worst smoothness  worst compactness  worst concavity  \\\n0   -0.440416         -0.606004          -0.201842        -0.297585   \n1   -0.471384         -1.113169          -1.131298        -1.048863   \n2   -0.592795         -0.841096          -0.669674        -0.715317   \n3   -1.153796          0.022669           0.187599        -0.337522   \n4   -0.658663         -0.933548          -1.095594        -0.795828   \n\n   worst concave points  worst symmetry  worst fractal dimension  \n0              0.036383       -0.329689                -0.541464  \n1             -0.509321       -1.059435                -0.933436  \n2             -0.117569       -0.719202                -0.952326  \n3             -0.017912        0.473386                 0.168230  \n4             -0.670833       -1.211613                -1.094003  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.634369</td>\n      <td>-1.602614</td>\n      <td>-0.573893</td>\n      <td>-0.706375</td>\n      <td>-0.602063</td>\n      <td>0.062874</td>\n      <td>-0.009837</td>\n      <td>-0.024047</td>\n      <td>-0.386483</td>\n      <td>-0.329722</td>\n      <td>...</td>\n      <td>-0.351774</td>\n      <td>-1.444948</td>\n      <td>-0.229655</td>\n      <td>-0.440416</td>\n      <td>-0.606004</td>\n      <td>-0.201842</td>\n      <td>-0.297585</td>\n      <td>0.036383</td>\n      <td>-0.329689</td>\n      <td>-0.541464</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.390155</td>\n      <td>-1.102783</td>\n      <td>-0.434304</td>\n      <td>-0.430659</td>\n      <td>-1.209809</td>\n      <td>-1.157665</td>\n      <td>-1.008900</td>\n      <td>-0.788759</td>\n      <td>-0.999615</td>\n      <td>-1.258113</td>\n      <td>...</td>\n      <td>-0.379523</td>\n      <td>-1.120854</td>\n      <td>-0.486640</td>\n      <td>-0.471384</td>\n      <td>-1.113169</td>\n      <td>-1.131298</td>\n      <td>-1.048863</td>\n      <td>-0.509321</td>\n      <td>-1.059435</td>\n      <td>-0.933436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.473453</td>\n      <td>-0.867409</td>\n      <td>-0.474384</td>\n      <td>-0.535007</td>\n      <td>-0.760951</td>\n      <td>-0.659168</td>\n      <td>-0.491093</td>\n      <td>-0.214902</td>\n      <td>-0.740019</td>\n      <td>-1.118265</td>\n      <td>...</td>\n      <td>-0.480554</td>\n      <td>-1.007848</td>\n      <td>-0.549392</td>\n      <td>-0.592795</td>\n      <td>-0.841096</td>\n      <td>-0.669674</td>\n      <td>-0.715317</td>\n      <td>-0.117569</td>\n      <td>-0.719202</td>\n      <td>-0.952326</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.256263</td>\n      <td>-0.926253</td>\n      <td>-1.198867</td>\n      <td>-1.228029</td>\n      <td>-0.166928</td>\n      <td>0.101521</td>\n      <td>-0.284908</td>\n      <td>-0.440548</td>\n      <td>-0.206685</td>\n      <td>0.459241</td>\n      <td>...</td>\n      <td>-1.096705</td>\n      <td>-0.956142</td>\n      <td>-1.083582</td>\n      <td>-1.153796</td>\n      <td>0.022669</td>\n      <td>0.187599</td>\n      <td>-0.337522</td>\n      <td>-0.017912</td>\n      <td>0.473386</td>\n      <td>0.168230</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.416659</td>\n      <td>-1.334775</td>\n      <td>-0.403898</td>\n      <td>-0.455261</td>\n      <td>-0.928867</td>\n      <td>-0.825416</td>\n      <td>-0.488282</td>\n      <td>-0.449494</td>\n      <td>-1.002645</td>\n      <td>-1.167128</td>\n      <td>...</td>\n      <td>-0.553838</td>\n      <td>-1.480129</td>\n      <td>-0.552380</td>\n      <td>-0.658663</td>\n      <td>-0.933548</td>\n      <td>-1.095594</td>\n      <td>-0.795828</td>\n      <td>-0.670833</td>\n      <td>-1.211613</td>\n      <td>-1.094003</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = -1 + (((X - X.mean())*2) / (X.max() - X.min()))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "### Bagging\n",
    "\n",
    "You can find bagging classifier in sklearn.ensembles.Bagging. For the bagging classifier we need a base model. We will use\n",
    "logistic regression as our base model. You can find the complete documentation on bagging classifier\n",
    "[here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html).\n",
    "\n",
    "Let's train a Bagging classifier with 10 estimators with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=LogisticRegression(max_iter=1000))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_log_reg = LogisticRegression(max_iter=1000)\n",
    "bag_clf = BaggingClassifier(base_estimator=base_log_reg, n_estimators=10)\n",
    "\n",
    "bag_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        54\n",
      "           1       0.98      1.00      0.99        89\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.98      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bag_clf.predict(X_test)\n",
    "print(classification_report(y_pred=pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "The most popular ensemble method is the random forest classifier. You can find the full documentation on random\n",
    "forest implementation [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "Let's train a random forest model with 200 trees where the maximum depth of each tree is two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(max_depth=2, n_estimators=200)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=2)\n",
    "rf_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the performance of it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        54\n",
      "           1       0.97      0.99      0.98        89\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_pred=pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier\n",
    "Implementation of voting classifier can be found in\n",
    "[sklearn.ensemble.VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier).\n",
    "This implementation supports weighted voting as well.\n",
    "\n",
    "We are going to train a voting classifier with three classifiers, a Logistic Regression classifier, a Random Forest classifier\n",
    " and a Decision Tree classifier, with uniform weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('decTree', DecisionTreeClassifier()),\n                             ('LogReg', LogisticRegression(max_iter=1000)),\n                             ('RandForest', RandomForestClassifier())])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "log_reg_clf = LogisticRegression(max_iter=1000)\n",
    "randf_clf = RandomForestClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier([('decTree', tree_clf), ('LogReg', log_reg_clf), ('RandForest', randf_clf)], weights=None)\n",
    "voting_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the performance of our voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        54\n",
      "           1       0.97      1.00      0.98        89\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = voting_clf.predict(X_test)\n",
    "print(classification_report(y_pred=pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "We will implement a model using Gradient Boosting algorithm. You can find more information about Gradient Boosting\n",
    "algorithm\n",
    "[here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)\n",
    "\n",
    "Let's train a gradient boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(n_estimators=200)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=200)\n",
    "gb_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        54\n",
      "           1       0.97      0.97      0.97        89\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = gb_clf.predict(X_test)\n",
    "print(classification_report(y_pred=pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, when we compare the results above, We can see that the logistic regression with bagging has the best\n",
    "performance for this particular dataset. This is a really nice example which shows that using more sophisticated\n",
    "algorithms does not always make your predictions better. Sometimes, simple solutions work better. However, That does\n",
    "not mean Bagging classifier is the better ensemble method than any one of other algorithms used here. But at least for this\n",
    "dataset, Bagging classifier gives the best model we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task\n",
    "\n",
    "Change the normalizing method to,\n",
    "* Min_max scalar\n",
    "* Mean scalar\n",
    "* standard scalar\n",
    "\n",
    "and see what happens to the performance of the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender systems\n",
    "We are using movie rating dataset for our lab. First, we have to import the ratings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   userId  movieId  rating  timestamp\n0       1        1     4.0  964982703\n1       1        3     4.0  964981247\n2       1        6     4.0  964982224\n3       1       47     5.0  964983815\n4       1       50     5.0  964982931",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data = pd.read_csv(\"ratings.csv\")\n",
    "ratings_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset corresponds to one rating.\n",
    "* The userId column contains the ID of the user who left the rating.\n",
    "* The movieId column contains the ID of the movie\n",
    "* The rating column contains the rating left by the user. Ratings can have values between 1 and 5.\n",
    "* The timestamp refers to the time at which the user left the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains the IDs of the movies but not their titles. We'll need movie names for the movies we're\n",
    "rating. The movie names are stored in the \"movies.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_names = pd.read_csv(\"movies.csv\")\n",
    "movie_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9742 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9742 non-null   int64 \n",
      " 1   title    9742 non-null   object\n",
      " 2   genres   9742 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_names.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a dataset that contains the userId, movie title, and its ratings. We have this information in two different\n",
    "dataframe objects: \"ratings_data\" and \"movie_names\". To get our desired information in a single dataframe, we can\n",
    "merge the two dataframe objects on the movieId column since it is common between the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   userId  movieId  rating   timestamp             title  \\\n0       1        1     4.0   964982703  Toy Story (1995)   \n1       5        1     4.0   847434962  Toy Story (1995)   \n2       7        1     4.5  1106635946  Toy Story (1995)   \n3      15        1     2.5  1510577970  Toy Story (1995)   \n4      17        1     4.5  1305696483  Toy Story (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1  Adventure|Animation|Children|Comedy|Fantasy  \n2  Adventure|Animation|Children|Comedy|Fantasy  \n3  Adventure|Animation|Children|Comedy|Fantasy  \n4  Adventure|Animation|Children|Comedy|Fantasy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>847434962</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1106635946</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>1510577970</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1305696483</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data = pd.merge(ratings_data, movie_names, on='movieId')\n",
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100836 entries, 0 to 100835\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      " 4   title      100836 non-null  object \n",
      " 5   genres     100836 non-null  object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "movie_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(movie_data, test_size=0.3, random_state=42)\n",
    "\n",
    "datasets = [train_data, test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to create a dataset which represent all the rating of a user in a single instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    1      3      6      47     50     70     101    110    151    157     \\\n488    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n129    NaN    NaN    NaN    3.5    NaN    NaN    NaN    NaN    NaN    NaN   \n489    NaN    NaN    NaN    3.0    NaN    2.0    NaN    4.5    3.5    NaN   \n509    4.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n200    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n\n     ... 147662 148166 149011 152372 158721 160341 160527 160836 163937 163981  \n488  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n129  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n489  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n509  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n200  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n\n[5 rows x 9724 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>3</th>\n      <th>6</th>\n      <th>47</th>\n      <th>50</th>\n      <th>70</th>\n      <th>101</th>\n      <th>110</th>\n      <th>151</th>\n      <th>157</th>\n      <th>...</th>\n      <th>147662</th>\n      <th>148166</th>\n      <th>149011</th>\n      <th>152372</th>\n      <th>158721</th>\n      <th>160341</th>\n      <th>160527</th>\n      <th>160836</th>\n      <th>163937</th>\n      <th>163981</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>488</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>489</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 9724 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating_df = pd.DataFrame(index=train_data['userId'].unique(), columns=movie_data['movieId'].unique())\n",
    "for index, row in train_data.iterrows():\n",
    "    user_rating_df[row['movieId']][row['userId']] = row['rating']\n",
    "\n",
    "user_rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here onwards **you are going to** implement the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the datasets ready, now we can use the pairwise distance functions or pandas corr() method to create the\n",
    "correlation matrices for both training sets. We are going to use pearson correlation. You can find the information on\n",
    " pairwise distance\n",
    "[here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html). And the information\n",
    "about the metric you are going to use can be found\n",
    "[here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.correlation.html).\n",
    "\n",
    "Note:\n",
    "* The pairwise distance function calculates the distance, not the similarity.\n",
    "* Replace Nan with 0.\n",
    "* Normalizing the data is really important for user-based CF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate user similarity matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate item similarity matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the similarity matrices in hand, we can now predict the ratings that were not included with the data. We can compare these predictions with the test data to validate the quality of our recommender model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user-based CF we are using k-nearest neighbours. The steps are,\n",
    "* Rank all the users and find the top-k most similar users for a particular user in the training set.\n",
    "* Using average, aggregate the ratings of the k nearest neighbours as the prediction.\n",
    "* Return the predictions.\n",
    "\n",
    "Create a function that takes the training set, the user similarity matrix, K (number of neighbours considering) and\n",
    "user_Id as inputs and return the predicted rating values for that user for all the movies.\n",
    "\n",
    "i.e:\n",
    "for this dataset\n",
    "* for user 509, predicted normalized rating for movie Id 50 is 0.3333\n",
    "* for user 19, predicted normalized rating for movie Id 260 is 0.5833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your function here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function that takes the training set, the item similarity matrix, K (number of neighbours considering) and\n",
    "movie_Id as inputs and return the predicted rating values for all the users using item-based CF.\n",
    "\n",
    "i.e:\n",
    "for this dataset\n",
    "* for user 63, predicted normalized rating for movie Id 50 is 0.4444\n",
    "* for user 19, predicted normalized rating for movie Id 260 is 0.4167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your function here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We are going to use Root Mean Square Error (RMSE) as our evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation steps are follows.\n",
    "* Using the implemented function generate a complete training set.\n",
    "* For each instance in test set,\n",
    "    * Check whether that UserID and Movie Id exists on the completed training set. If not skip.\n",
    "    * Get the predicted rating from the completed training set and measure the error.\n",
    "* Using the error values calculate the RMSE for your prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the user-based CF model performance. Please normalize the test data using the same values you used to\n",
    "normalize train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the item-based CF model performance here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
